{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550fe726-542f-47d2-ab73-2905ae98b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torchvision as TV\n",
    "import torchaudio as TA\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm as tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536f24c4-31da-4781-8b6f-03a75276059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if T.cuda.is_available():\n",
    "    device=T.device(\"cuda\")\n",
    "else:\n",
    "    device=T.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f30aa41-32ab-4d82-8665-74505221a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Paths ----------\n",
    "train_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\train_new\"\n",
    "train_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\trainlabel_new\"\n",
    "validation_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\validation_new\"\n",
    "validation_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\validationlabel_new\"\n",
    "test_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\test_new\"\n",
    "test_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\testlabel_new\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e07beed-1b72-458b-b846-23816cd8bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying Training File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [00:00<00:00, 99989.37it/s]\n",
      "Verifying Validation File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 58675.58it/s]\n",
      "Verifying Testing File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:00<00:00, 60010.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Augmentations -----------------------\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.ElasticTransform(p=0.5),\n",
    "    A.D4(p=1),\n",
    "    A.ISONoise(\n",
    "        color_shift=[0.01, 0.05],\n",
    "        intensity=[0.1, 0.5],\n",
    "        p=0.5\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.2], contrast_limit=[-0.2, 0.2], brightness_by_max=True, ensure_safe_range=False, p=0.5),\n",
    "    A.ElasticTransform(\n",
    "        alpha=300,\n",
    "        sigma=10,\n",
    "        interpolation=cv2.INTER_NEAREST,\n",
    "        approximate=False,\n",
    "        same_dxdy=True,\n",
    "        mask_interpolation=cv2.INTER_NEAREST,\n",
    "        noise_distribution=\"gaussian\",\n",
    "        keypoint_remapping_method=\"mask\",\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        fill=0,\n",
    "        fill_mask=0\n",
    "    ),\n",
    "])\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ---------------------- Dataset Class -----------------------\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, train_transform=None, base_transform=None, dataset_type=\"Unknown\"):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.train_transform = train_transform\n",
    "        self.base_transform = base_transform\n",
    "        self.dataset_type = dataset_type\n",
    "        self.image_files = sorted(glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.mask_files = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n",
    "        self._verify_file_pairs()\n",
    "        \n",
    "    def _verify_file_pairs(self):\n",
    "        if len(self.image_files) != len(self.mask_files):\n",
    "            raise ValueError(f\"Mismatched counts in {self.dataset_type} dataset: {len(self.image_files)} images vs {len(self.mask_files)} masks\")\n",
    "            \n",
    "        for img_path, mask_path in tqdm(zip(self.image_files, self.mask_files), total=len(self.image_files), desc=f\"Verifying {self.dataset_type} File Pairs üîç\"):\n",
    "            img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            mask_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "            if img_name != mask_name:\n",
    "                raise ValueError(f\"Filename mismatch in {self.dataset_type} dataset: {img_name} vs {mask_name}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.image_files[idx]), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_files[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        original_img = self.base_transform(T.from_numpy(img).permute(2, 0, 1).float()).to(device)\n",
    "        original_mask = T.from_numpy(mask).long().to(device)  # Convert mask to tensor directly\n",
    "        \n",
    "        if self.train_transform:\n",
    "            augmented = self.train_transform(image=img, mask=mask)\n",
    "            aug_img = augmented['image']\n",
    "            aug_mask = augmented['mask']\n",
    "            aug_img = self.base_transform(T.from_numpy(aug_img).permute(2, 0, 1).float()).to(device)\n",
    "            aug_mask = T.from_numpy(aug_mask).long().to(device)\n",
    "            \n",
    "            return {\n",
    "                'original_img': original_img,\n",
    "                'original_mask': original_mask,\n",
    "                'augmented_img': aug_img,\n",
    "                'augmented_mask': aug_mask\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'original_img': original_img,\n",
    "                'original_mask': original_mask\n",
    "            }\n",
    "\n",
    "# ---------------------- Datasets & DataLoaders -----------------------\n",
    "train_dataset = SegmentationDataset(\n",
    "    train_images, \n",
    "    train_masks, \n",
    "    train_transform=train_transform,\n",
    "    base_transform=base_transform,\n",
    "    dataset_type=\"Training\"\n",
    ")\n",
    "\n",
    "val_dataset = SegmentationDataset(\n",
    "    validation_images,\n",
    "    validation_masks,\n",
    "    train_transform=train_transform,\n",
    "    base_transform=base_transform,\n",
    "    dataset_type=\"Validation\"\n",
    ")\n",
    "\n",
    "test_dataset = SegmentationDataset(\n",
    "    test_images,\n",
    "    test_masks,\n",
    "    train_transform=train_transform,\n",
    "    base_transform=base_transform,\n",
    "    dataset_type=\"Testing\"\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be818f64-94c3-4db7-a586-a89cde69df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Model Definition -----------------------\n",
    "model = smp.Unet(\n",
    "    encoder=\"efficientnet-b7\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_depth=4,\n",
    "    decoder_use_batchnorm='inplace',\n",
    "    decoder_attention_type='scse',\n",
    "    decoder_channels=[256, 128, 64, 32],\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    "    activation=\"softmax\",\n",
    "    center=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ---------------------- Loss Functions -----------------------\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, ep=1e-6):\n",
    "        super(TverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.ep = ep\n",
    "\n",
    "    def update_params(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        targets_one_hot = T.nn.functional.one_hot(targets, num_classes=2).permute(0, 3, 1, 2).float()\n",
    "        preds = outputs \n",
    "        true = targets_one_hot\n",
    "        TP = (preds * true).sum(dim=[2, 3])\n",
    "        FP = (preds * (1 - true)).sum(dim=[2, 3])\n",
    "        FN = ((1 - preds) * true).sum(dim=[2, 3])\n",
    "        tversky = (TP + self.ep) / (TP + self.alpha * FP + self.beta * FN + self.ep)\n",
    "        return 1 - tversky.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, focal_weight=0.5, tversky_weight=0.5, tversky_alpha=0.7, tversky_beta=0.3):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.focal_loss = smp.losses.FocalLoss(mode='multiclass')\n",
    "        self.tversky_loss = TverskyLoss(alpha=tversky_alpha, beta=tversky_beta)\n",
    "        self.focal_weight = focal_weight\n",
    "        self.tversky_weight = tversky_weight\n",
    "\n",
    "    def forward(self, outputs, targets, return_components=False):\n",
    "        focal = self.focal_loss(outputs, targets)\n",
    "        tversky = self.tversky_loss(outputs, targets)\n",
    "        total_loss = self.focal_weight * focal + self.tversky_weight * tversky\n",
    "        if return_components:\n",
    "            return total_loss, focal, tversky\n",
    "        return total_loss\n",
    "\n",
    "# ---------------------- Dynamic Loss Wrapper -----------------------\n",
    "class DynamicLossWrapper:\n",
    "    def __init__(self, criterion, recall_threshold=0.8):\n",
    "        self.criterion = criterion\n",
    "        self.recall_threshold = recall_threshold\n",
    "        self.focal_losses = []\n",
    "        self.tversky_losses = []\n",
    "\n",
    "    def update_weights(self):\n",
    "        if len(self.focal_losses) > 0 and len(self.tversky_losses) > 0:\n",
    "            avg_focal = np.mean(self.focal_losses[-5:])  # Last 5 epochs\n",
    "            avg_tversky = np.mean(self.tversky_losses[-5:])  # Last 5 epochs\n",
    "            total = avg_focal + avg_tversky\n",
    "            if total > 0:\n",
    "                self.criterion.focal_weight = avg_tversky / total\n",
    "                self.criterion.tversky_weight = avg_focal / total\n",
    "            self.focal_losses = []\n",
    "            self.tversky_losses = []\n",
    "\n",
    "    def update_tversky_params(self, recall):\n",
    "        alpha = self.criterion.tversky_loss.alpha\n",
    "        if recall < self.recall_threshold:\n",
    "            alpha = min(alpha + 0.05, 0.9)  # Increase alpha for better recall\n",
    "        else:\n",
    "            alpha = max(alpha - 0.05, 0.5)  # Decrease alpha for balanced precision\n",
    "        beta = 1.0 - alpha\n",
    "        self.criterion.tversky_loss.update_params(alpha, beta)\n",
    "        return alpha, beta\n",
    "\n",
    "    def __call__(self, outputs, targets):\n",
    "        loss, focal, tversky = self.criterion(outputs, targets, return_components=True)\n",
    "        self.focal_losses.append(focal.item())\n",
    "        self.tversky_losses.append(tversky.item())\n",
    "        return loss\n",
    "\n",
    "# ---------------------- Metrics -----------------------\n",
    "def compute_accuracy(outputs, targets):\n",
    "    preds = T.argmax(outputs, dim=1)  # [batch, H, W]\n",
    "    correct = (preds == targets).float().sum()\n",
    "    total = targets.numel()\n",
    "    return (correct / total).item()\n",
    "\n",
    "def compute_iou(outputs, targets, class_id=1):  # IoU for foreground (class_id=1)\n",
    "    preds = (T.argmax(outputs, dim=1) == class_id).float()  # [batch, H, W]\n",
    "    targets = (targets == class_id).float()  # [batch, H, W]\n",
    "    intersection = (preds * targets).sum((1, 2))\n",
    "    union = (preds + targets - preds * targets).sum((1, 2))\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.mean().item()\n",
    "\n",
    "def compute_miou(outputs, targets, num_classes=2):\n",
    "    ious = []\n",
    "    for class_id in range(num_classes):\n",
    "        preds = (T.argmax(outputs, dim=1) == class_id).float()\n",
    "        targets_class = (targets == class_id).float()\n",
    "        intersection = (preds * targets_class).sum((1, 2))\n",
    "        union = (preds + targets_class - preds * targets_class).sum((1, 2))\n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "        ious.append(iou)\n",
    "    return T.stack(ious).mean().item()\n",
    "\n",
    "def compute_map(outputs, targets, iou_thresholds=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]):\n",
    "    preds = T.argmax(outputs, dim=1)  # [batch, H, W]\n",
    "    targets = targets\n",
    "    aps = []\n",
    "    for threshold in iou_thresholds:\n",
    "        iou = compute_iou(outputs, targets, class_id=1)\n",
    "        ap = 1.0 if iou >= threshold else 0.0\n",
    "        aps.append(ap)\n",
    "    return np.mean(aps)\n",
    "\n",
    "def compute_fnr(outputs, targets, class_id=1):\n",
    "    preds = (T.argmax(outputs, dim=1) == class_id).float()  # [batch, H, W]\n",
    "    targets = (targets == class_id).float()  # [batch, H, W]\n",
    "    FN = ((1 - preds) * targets).sum((1, 2))\n",
    "    TP = (preds * targets).sum((1, 2))\n",
    "    fnr = (FN + 1e-6) / (TP + FN + 1e-6)\n",
    "    return fnr.mean().item()\n",
    "\n",
    "def compute_recall(outputs, targets, class_id=1):\n",
    "    preds = (T.argmax(outputs, dim=1) == class_id).float()  # [batch, H, W]\n",
    "    targets = (targets == class_id).float()  # [batch, H, W]\n",
    "    TP = (preds * targets).sum((1, 2))\n",
    "    FN = ((1 - preds) * targets).sum((1, 2))\n",
    "    recall = (TP + 1e-6) / (TP + FN + 1e-6)\n",
    "    return recall.mean().item()\n",
    "\n",
    "def compute_precision(outputs, targets, class_id=1):\n",
    "    preds = (T.argmax(outputs, dim=1) == class_id).float()  # [batch, H, W]\n",
    "    targets = (targets == class_id).float()  # [batch, H, W]\n",
    "    TP = (preds * targets).sum((1, 2))\n",
    "    FP = (preds * (1 - targets)).sum((1, 2))\n",
    "    precision = (TP + 1e-6) / (TP + FP + 1e-6)\n",
    "    return precision.mean().item()\n",
    "\n",
    "def compute_f1_score(outputs, targets, class_id=1):\n",
    "    precision = compute_precision(outputs, targets, class_id)\n",
    "    recall = compute_recall(outputs, targets, class_id)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    return f1\n",
    "\n",
    "def compute_confusion_matrix(outputs, targets, class_id=1):\n",
    "    preds = (T.argmax(outputs, dim=1) == class_id).float()  # [batch, H, W]\n",
    "    targets = (targets == class_id).float()  # [batch, H, W]\n",
    "    TP = (preds * targets).sum().item()\n",
    "    FP = (preds * (1 - targets)).sum().item()\n",
    "    FN = ((1 - preds) * targets).sum().item()\n",
    "    TN = ((1 - preds) * (1 - targets)).sum().item()\n",
    "    return {'TP': TP, 'FP': FP, 'FN': FN, 'TN': TN}\n",
    "\n",
    "# ---------------------- Training and Testing -----------------------\n",
    "def train_model(model, train_dataloader, val_dataloader, test_dataloader, epochs=50):\n",
    "    criterion = CombinedLoss(focal_weight=0.5, tversky_weight=0.5, tversky_alpha=0.7, tversky_beta=0.3).to(device)\n",
    "    dynamic_loss = DynamicLossWrapper(criterion, recall_threshold=0.8)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_accuracy = 0.0\n",
    "        train_iou = 0.0\n",
    "        train_miou = 0.0\n",
    "        train_map = 0.0\n",
    "        train_fnr = 0.0\n",
    "        train_precision = 0.0\n",
    "        train_f1 = 0.0\n",
    "        \n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\", leave=False):\n",
    "            original_imgs = batch['original_img']\n",
    "            original_masks = batch['original_mask']\n",
    "            augmented_imgs = batch['augmented_img']\n",
    "            augmented_masks = batch['augmented_mask']\n",
    "            \n",
    "            all_imgs = T.cat([original_imgs, augmented_imgs], dim=0)\n",
    "            all_masks = T.cat([original_masks, augmented_masks], dim=0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(all_imgs)\n",
    "            loss = dynamic_loss(outputs, all_masks)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * all_imgs.size(0)\n",
    "            train_accuracy += compute_accuracy(outputs, all_masks) * all_imgs.size(0)\n",
    "            train_iou += compute_iou(outputs, all_masks) * all_imgs.size(0)\n",
    "            train_miou += compute_miou(outputs, all_masks) * all_imgs.size(0)\n",
    "            train_map += compute_map(outputs, all_masks) * all_imgs.size(0)\n",
    "            train_fnr += compute_fnr(outputs, all_masks) * all_imgs.size(0)\n",
    "            train_precision += compute_precision(outputs, all_masks) * all_imgs.size(0)\n",
    "            train_f1 += compute_f1_score(outputs, all_masks) * all_imgs.size(0)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        val_iou = 0.0\n",
    "        val_miou = 0.0\n",
    "        val_map = 0.0\n",
    "        val_fnr = 0.0\n",
    "        val_precision = 0.0\n",
    "        val_f1 = 0.0\n",
    "        val_recall = 0.0\n",
    "        if epoch == epochs - 1:  # Compute confusion matrix only for final epoch\n",
    "            val_cm = {'TP': 0, 'FP': 0, 'FN': 0, 'TN': 0}\n",
    "        \n",
    "        with T.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=\"Validation\", leave=False):\n",
    "                imgs = batch['original_img']  # Already on GPU\n",
    "                masks = batch['original_mask']  # Already on GPU\n",
    "                \n",
    "                outputs = model(imgs)\n",
    "                loss = dynamic_loss(outputs, masks)\n",
    "                \n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                val_accuracy += compute_accuracy(outputs, masks) * imgs.size(0)\n",
    "                val_iou += compute_iou(outputs, masks) * imgs.size(0)\n",
    "                val_miou += compute_miou(outputs, masks) * imgs.size(0)\n",
    "                val_map += compute_map(outputs, masks) * imgs.size(0)\n",
    "                val_fnr += compute_fnr(outputs, masks) * imgs.size(0)\n",
    "                val_precision += compute_precision(outputs, masks) * imgs.size(0)\n",
    "                val_f1 += compute_f1_score(outputs, masks) * imgs.size(0)\n",
    "                val_recall += compute_recall(outputs, masks) * imgs.size(0)\n",
    "                \n",
    "                if epoch == epochs - 1:  # Accumulate confusion matrix\n",
    "                    batch_cm = compute_confusion_matrix(outputs, masks)\n",
    "                    val_cm['TP'] += batch_cm['TP']\n",
    "                    val_cm['FP'] += batch_cm['FP']\n",
    "                    val_cm['FN'] += batch_cm['FN']\n",
    "                    val_cm['TN'] += batch_cm['TN']\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        train_loss = train_loss / (2 * len(train_dataloader.dataset))  # 2x for original + augmented\n",
    "        train_accuracy = train_accuracy / (2 * len(train_dataloader.dataset))\n",
    "        train_iou = train_iou / (2 * len(train_dataloader.dataset))\n",
    "        train_miou = train_miou / (2 * len(train_dataloader.dataset))\n",
    "        train_map = train_map / (2 * len(train_dataloader.dataset))\n",
    "        train_fnr = train_fnr / (2 * len(train_dataloader.dataset))\n",
    "        train_precision = train_precision / (2 * len(train_dataloader.dataset))\n",
    "        train_f1 = train_f1 / (2 * len(train_dataloader.dataset))\n",
    "        val_loss = val_loss / len(val_dataloader.dataset)\n",
    "        val_accuracy = val_accuracy / len(val_dataloader.dataset)\n",
    "        val_iou = val_iou / len(val_dataloader.dataset)\n",
    "        val_miou = val_miou / len(val_dataloader.dataset)\n",
    "        val_map = val_map / len(val_dataloader.dataset)\n",
    "        val_fnr = val_fnr / len(val_dataloader.dataset)\n",
    "        val_precision = val_precision / len(val_dataloader.dataset)\n",
    "        val_f1 = val_f1 / len(val_dataloader.dataset)\n",
    "        val_recall = val_recall / len(val_dataloader.dataset)\n",
    "        \n",
    "        # Update dynamic hyperparameters\n",
    "        dynamic_loss.update_weights()\n",
    "        tversky_alpha, tversky_beta = dynamic_loss.update_tversky_params(val_recall)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "              f'Train IoU: {train_iou:.4f}, Train MIoU: {train_miou:.4f}, Train mAP: {train_map:.4f}, '\n",
    "              f'Train FNR: {train_fnr:.4f}, Train Precision: {train_precision:.4f}, Train F1: {train_f1:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val IoU: {val_iou:.4f}, '\n",
    "              f'Val MIoU: {val_miou:.4f}, Val mAP: {val_map:.4f}, Val FNR: {val_fnr:.4f}, '\n",
    "              f'Val Precision: {val_precision:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_recall:.4f}, '\n",
    "              f'Focal Weight: {dynamic_loss.criterion.focal_weight:.3f}, '\n",
    "              f'Tversky Weight: {dynamic_loss.criterion.tversky_weight:.3f}, '\n",
    "              f'Tversky Alpha: {tversky_alpha:.3f}, Beta: {tversky_beta:.3f}')\n",
    "        \n",
    "        # Print validation confusion matrix for final epoch\n",
    "        if epoch == epochs - 1:\n",
    "            total = val_cm['TP'] + val_cm['FP'] + val_cm['FN'] + val_cm['TN']\n",
    "            if total > 0:\n",
    "                cm_normalized = {\n",
    "                    'TP': val_cm['TP'] / total,\n",
    "                    'FP': val_cm['FP'] / total,\n",
    "                    'FN': val_cm['FN'] / total,\n",
    "                    'TN': val_cm['TN'] / total\n",
    "                }\n",
    "                print(\"\\nFinal Validation Confusion Matrix (Normalized):\")\n",
    "                print(f\"{'':>10} {'Predicted':>20}\")\n",
    "                print(f\"{'':>10} {'Positive':>10} {'Negative':>10}\")\n",
    "                print(f\"{'Actual':>10}\")\n",
    "                print(f\"{'Positive':>10} {cm_normalized['TP']:.4f} {cm_normalized['FN']:.4f}\")\n",
    "                print(f\"{'Negative':>10} {cm_normalized['FP']:.4f} {cm_normalized['TN']:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            T.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    # Testing Phase\n",
    "    print(\"\\nEvaluating on Test Set...\")\n",
    "    model.load_state_dict(T.load('best_model.pth'))  # Load best model\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    test_iou = 0.0\n",
    "    test_miou = 0.0\n",
    "    test_map = 0.0\n",
    "    test_fnr = 0.0\n",
    "    test_precision = 0.0\n",
    "    test_f1 = 0.0\n",
    "    test_recall = 0.0\n",
    "    test_cm = {'TP': 0, 'FP': 0, 'FN': 0, 'TN': 0}\n",
    "    \n",
    "    with T.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            imgs = batch['original_img']  # Already on GPU\n",
    "            masks = batch['original_mask']  # Already on GPU\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = dynamic_loss(outputs, masks)\n",
    "            \n",
    "            test_loss += loss.item() * imgs.size(0)\n",
    "            test_accuracy += compute_accuracy(outputs, masks) * imgs.size(0)\n",
    "            test_iou += compute_iou(outputs, masks) * imgs.size(0)\n",
    "            test_miou += compute_miou(outputs, masks) * imgs.size(0)\n",
    "            test_map += compute_map(outputs, masks) * imgs.size(0)\n",
    "            test_fnr += compute_fnr(outputs, masks) * imgs.size(0)\n",
    "            test_precision += compute_precision(outputs, masks) * imgs.size(0)\n",
    "            test_f1 += compute_f1_score(outputs, masks) * imgs.size(0)\n",
    "            test_recall += compute_recall(outputs, masks) * imgs.size(0)\n",
    "            \n",
    "            # Accumulate confusion matrix\n",
    "            batch_cm = compute_confusion_matrix(outputs, masks)\n",
    "            test_cm['TP'] += batch_cm['TP']\n",
    "            test_cm['FP'] += batch_cm['FP']\n",
    "            test_cm['FN'] += batch_cm['FN']\n",
    "            test_cm['TN'] += batch_cm['TN']\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_loss = test_loss / len(test_dataloader.dataset)\n",
    "    test_accuracy = test_accuracy / len(test_dataloader.dataset)\n",
    "    test_iou = test_iou / len(test_dataloader.dataset)\n",
    "    test_miou = test_miou / len(test_dataloader.dataset)\n",
    "    test_map = test_map / len(test_dataloader.dataset)\n",
    "    test_fnr = test_fnr / len(test_dataloader.dataset)\n",
    "    test_precision = test_precision / len(test_dataloader.dataset)\n",
    "    test_f1 = test_f1 / len(test_dataloader.dataset)\n",
    "    test_recall = test_recall / len(test_dataloader.dataset)\n",
    "    \n",
    "    print(f'\\nTest Results - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, '\n",
    "          f'Test IoU: {test_iou:.4f}, Test MIoU: {test_miou:.4f}, Test mAP: {test_map:.4f}, '\n",
    "          f'Test FNR: {test_fnr:.4f}, Test Precision: {test_precision:.4f}, Test F1: {test_f1:.4f}, '\n",
    "          f'Test Recall: {test_recall:.4f}')\n",
    "    \n",
    "    # Print test confusion matrix\n",
    "    total = test_cm['TP'] + test_cm['FP'] + test_cm['FN'] + test_cm['TN']\n",
    "    if total > 0:\n",
    "        cm_normalized = {\n",
    "            'TP': test_cm['TP'] / total,\n",
    "            'FP': test_cm['FP'] / total,\n",
    "            'FN': test_cm['FN'] / total,\n",
    "            'TN': test_cm['TN'] / total\n",
    "        }\n",
    "        print(\"\\nTest Confusion Matrix (Normalized):\")\n",
    "        print(f\"{'':>10} {'Predicted':>20}\")\n",
    "        print(f\"{'':>10} {'Positive':>10} {'Negative':>10}\")\n",
    "        print(f\"{'Actual':>10}\")\n",
    "        print(f\"{'Positive':>10} {cm_normalized['TP']:.4f} {cm_normalized['FN']:.4f}\")\n",
    "        print(f\"{'Negative':>10} {cm_normalized['FP']:.4f} {cm_normalized['TN']:.4f}\")\n",
    "\n",
    "# Start training and testing\n",
    "train_model(model, train_dataloader, val_dataloader, test_dataloader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bae16a-75be-48df-b886-5a860482107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Model Definition -----------------------\n",
    "model = smp.Unet(\n",
    "    encoder=\"efficientnet-b7\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_depth=4,\n",
    "    decoder_use_batchnorm='inplace',\n",
    "    decoder_attention_type='scse',\n",
    "    decoder_channels=[256, 128, 64, 32],\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    "    activation=\"softmax\",\n",
    "    center=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ---------------------- Focal-Tversky Loss -----------------------\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=0.75, smooth=1e-6):\n",
    "        super(FocalTverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        probs = preds  # Assume softmax\n",
    "\n",
    "        dims = (0, 2, 3)\n",
    "        TP = T.sum(probs * targets_one_hot, dims)\n",
    "        FP = T.sum(probs * (1 - targets_one_hot), dims)\n",
    "        FN = T.sum((1 - probs) * targets_one_hot, dims)\n",
    "\n",
    "        Tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        return T.mean((1 - Tversky) ** self.gamma)\n",
    "\n",
    "# ---------------------- Evaluation Metrics -----------------------\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, average_precision_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_metrics(preds, targets, num_classes=2):\n",
    "    with T.no_grad():\n",
    "        preds = T.argmax(preds, dim=1).cpu().numpy().flatten()\n",
    "        targets = targets.cpu().numpy().flatten()\n",
    "\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        f1 = f1_score(targets, preds, average='binary' if num_classes == 2 else 'macro')\n",
    "        precision = precision_score(targets, preds, average='binary' if num_classes == 2 else 'macro')\n",
    "        recall = recall_score(targets, preds, average='binary' if num_classes == 2 else 'macro')\n",
    "        cm = confusion_matrix(targets, preds, labels=list(range(num_classes)))\n",
    "\n",
    "        if num_classes == 2:\n",
    "            TN, FP, FN, TP = cm.ravel()\n",
    "            fnr = FN / (FN + TP + 1e-6)\n",
    "        else:\n",
    "            fnr = None\n",
    "\n",
    "        ious = []\n",
    "        for cls in range(num_classes):\n",
    "            intersection = ((preds == cls) & (targets == cls)).sum()\n",
    "            union = ((preds == cls) | (targets == cls)).sum()\n",
    "            iou = intersection / (union + 1e-6)\n",
    "            ious.append(iou)\n",
    "\n",
    "        mean_iou = sum(ious) / num_classes\n",
    "\n",
    "        return {\n",
    "            \"Accuracy\": acc,\n",
    "            \"F1-Score\": f1,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"IoU (Foreground)\": ious[1] if num_classes > 1 else ious[0],\n",
    "            \"Mean IoU\": mean_iou,\n",
    "            \"FNR\": fnr\n",
    "        }\n",
    "\n",
    "# ---------------------- Optimizer -----------------------\n",
    "optimizer = T.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# ---------------------- LR Scheduler -----------------------\n",
    "scheduler = T.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # use 'max' if monitoring a metric like Mean IoU\n",
    "    factor=0.5,          # reduce LR by half\n",
    "    patience=3,          # wait for 3 bad epochs before reducing\n",
    "    threshold=1e-4,      # minimum improvement to avoid being a bad epoch\n",
    "    threshold_mode='rel',\n",
    "    cooldown=0,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True         # print when LR is updated\n",
    ")\n",
    "\n",
    "# ---------------------- Dynamic Focal-Tversky Logic ----------------------\n",
    "# Updated logic for strong performance in 50 epochs:\n",
    "# - Update alpha, beta, gamma every 5 epochs (10 steps total)\n",
    "# - Alpha linearly decreases from 0.7 to 0.4, beta increases from 0.3 to 0.6\n",
    "# - Gamma increases from 0.75 to 1.5\n",
    "\n",
    "def update_ft_params(epoch):\n",
    "    steps = epoch // 5  # one step every 5 epochs\n",
    "    alpha = max(0.4, 0.7 - 0.03 * steps)  # from 0.7 to 0.4\n",
    "    beta = 1 - alpha                      # from 0.3 to 0.6\n",
    "    gamma = min(1.5, 0.75 + 0.075 * steps)  # from 0.75 to 1.5\n",
    "    return alpha, beta, gamma\n",
    "\n",
    "# ---------------------- Training & Validation Loops ----------------------\n",
    "def TrainUNet(model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['augmented_img']\n",
    "        targets = batch['augmented_mask']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append(outputs.detach())\n",
    "        all_targets.append(targets.detach())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    all_preds = T.cat(all_preds, dim=0)\n",
    "    all_targets = T.cat(all_targets, dim=0)\n",
    "\n",
    "    metrics = compute_metrics(all_preds, all_targets)\n",
    "    return avg_loss, metrics\n",
    "\n",
    "\n",
    "def ValidateUNet(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with T.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch['original_img']\n",
    "            targets = batch['original_mask']\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            all_preds.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    all_preds = T.cat(all_preds, dim=0)\n",
    "    all_targets = T.cat(all_targets, dim=0)\n",
    "\n",
    "    metrics = compute_metrics(all_preds, all_targets)\n",
    "    return avg_loss, metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
