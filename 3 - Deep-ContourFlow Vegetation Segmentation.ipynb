{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b263a116-ec67-45df-ab0f-db7f00974397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c942ca-872a-48d2-95cb-f8f9a042abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\"\n",
    "DEVICE = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4478d637-ac91-4999-865a-debf790dc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropWeedDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.image_paths = glob(os.path.join(folder_path, \"*.jpg\"))\n",
    "        self.image_paths += glob(os.path.join(folder_path, \"*.png\"))\n",
    "\n",
    "        def natural_key(string):\n",
    "            return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string)]\n",
    "\n",
    "        self.image_paths.sort(key=natural_key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img_tensor = T.from_numpy(img).permute(2, 0, 1).contiguous()\n",
    "\n",
    "        return img_tensor.to(DEVICE), img_path\n",
    "\n",
    "def get_loader(folder_path, batch_size=4):\n",
    "    dataset = CropWeedDataset(folder_path)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "train_path = os.path.join(BASE_PATH, \"train_new\")\n",
    "val_path   = os.path.join(BASE_PATH, \"validation_new\")\n",
    "test_path  = os.path.join(BASE_PATH, \"test_new\")\n",
    "train_loader = get_loader(train_path)\n",
    "val_loader   = get_loader(val_path)\n",
    "test_loader  = get_loader(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421d5508-24cf-4237-88bf-fab96a79c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fused_contours(batch_imgs):\n",
    "    T.cuda.empty_cache()\n",
    "    fused_maps = []\n",
    "    batch_imgs_np = batch_imgs.detach().cpu().numpy()\n",
    "\n",
    "    for img in batch_imgs_np:\n",
    "        img_rgb = np.transpose(img, (1, 2, 0)) * 255.0\n",
    "        img_rgb = img_rgb.astype(np.uint8)\n",
    "        gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Sobel\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel = cv2.magnitude(sobelx, sobely)\n",
    "        sobel = np.clip(sobel / sobel.max(), 0, 1)\n",
    "\n",
    "        # Canny\n",
    "        canny = cv2.Canny(gray, 100, 200) / 255.0\n",
    "\n",
    "        # Fuse Sobel + Canny\n",
    "        fused = np.maximum(sobel, canny)\n",
    "\n",
    "        fused_tensor = T.tensor(fused, dtype=T.float32).unsqueeze(0)\n",
    "        fused_maps.append(fused_tensor)\n",
    "\n",
    "    fused_batch = T.stack(fused_maps).to(batch_imgs.device)\n",
    "    T.cuda.empty_cache()\n",
    "    return fused_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d470d62-5ad3-49b1-b78b-cd89454eefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRNetW32FeatureExtractor(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.backbone = timm.create_model(\n",
    "            \"hrnet_w32\", \n",
    "            pretrained=True, \n",
    "            features_only=True\n",
    "        ).to(self.device)\n",
    "\n",
    "        # HRNet returns multi-scale outputs (C1, C2, C3, C4)\n",
    "        # We'll use the highest-resolution one: index 0\n",
    "        self.selected_feature_idx = 0\n",
    "\n",
    "        # Freeze the backbone\n",
    "        self.backbone.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        with T.no_grad():\n",
    "            features = self.backbone(x)  # List of [B, C, H', W']\n",
    "            feature_map = features[self.selected_feature_idx]  # [B, 32, 96, 128]\n",
    "\n",
    "            # Upsample to match original input size (384√ó512)\n",
    "            feature_map_upsampled = F.interpolate(\n",
    "                feature_map,\n",
    "                size=(384, 512),\n",
    "                mode='bicubic',  # Better edge preservation\n",
    "                align_corners=False\n",
    "            )\n",
    "\n",
    "            return feature_map_upsampled  # [B, 32, 384, 512]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b8f183-0e30-4888-8726-690ac18732ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourFeatureFusion(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_fusion = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, cnn_features, edge_maps):\n",
    "        # cnn_features: [B, C1, H, W]\n",
    "        # edge_maps:    [B, 1, H, W]\n",
    "        x = T.cat([cnn_features, edge_maps], dim=1)  # [B, C1+1, H, W]\n",
    "        fused = self.conv_fusion(x)\n",
    "        return fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a05c3d4-1019-409f-bd44-25d579a5869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_kmeans(fused_features, n_clusters=2):\n",
    "    masks = []\n",
    "    fused_np = fused_features.detach().cpu().numpy()\n",
    "\n",
    "    for feat in tqdm(fused_np, desc=\"üß† Running K-Means on batch\"):\n",
    "        C, H, W = feat.shape\n",
    "        flat_feat = feat.reshape(C, -1).T\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "        labels = kmeans.fit_predict(flat_feat)\n",
    "\n",
    "        mask = labels.reshape(H, W)\n",
    "        masks.append(mask.astype(np.uint8))\n",
    "\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e0c965-29c2-40c1-9b06-45aa3b23f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_mask(mask, apply_opening=True, apply_closing=True, dilate=False):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    if apply_opening:\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    if apply_closing:\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    if dilate:\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def process_kmeans_with_centroids(fused_tensor, n_clusters=2):\n",
    "    C, H, W = fused_tensor.shape\n",
    "    flat_feat = fused_tensor.reshape(C, -1).T  # [H*W, C]\n",
    "\n",
    "    # Run KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "    labels = kmeans.fit_predict(flat_feat)      # [H*W]\n",
    "    centers = kmeans.cluster_centers_           # [2, C]\n",
    "\n",
    "    # Pick cluster with lower mean center value as foreground\n",
    "    foreground_label = np.argmin(centers.mean(axis=1))\n",
    "    mask = (labels == foreground_label).astype(np.uint8).reshape(H, W)\n",
    "\n",
    "    # Refine the mask using MorphOps\n",
    "    refined_mask = refine_mask(mask)\n",
    "    return refined_mask\n",
    "\n",
    "\n",
    "def batch_process_kmeans_masks_from_features(fused_features):\n",
    "    fused_np = fused_features.detach().cpu().numpy()\n",
    "    final_masks = []\n",
    "\n",
    "    for feat in tqdm(fused_np, desc=\"üß† Step 6: Refining Masks\", leave=False):\n",
    "        refined_mask = process_kmeans_with_centroids(feat)\n",
    "        final_masks.append(refined_mask)\n",
    "\n",
    "    return final_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c882732-308d-4bf7-9bf1-264c6bc07400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # ‚è±Ô∏è Make sure this is at the top of your script\n",
    "\n",
    "def batch_infer_masks(data_loader, model, device):\n",
    "    \"\"\"\n",
    "    Step 7: Batch inference using RGB + contour fusion ‚Üí KMeans ‚Üí MorphOps\n",
    "    Now includes timing per image.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    final_masks_all = []\n",
    "    image_paths_all = []\n",
    "\n",
    "    total_time = 0\n",
    "    total_images = 0\n",
    "\n",
    "    for batch_imgs, paths in tqdm(data_loader, desc=\"üì¶ Step 7: Batch Inference\", leave=False):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        start_time = time.time()  # ‚è±Ô∏è Start timing\n",
    "\n",
    "        with T.no_grad():\n",
    "            # Step 3: Feature extraction from RGB only\n",
    "            cnn_feats = model(batch_imgs)\n",
    "\n",
    "            # Step 2: Contour extraction from RGB\n",
    "            contour_maps = compute_fused_contours(batch_imgs)\n",
    "\n",
    "            # Step 4: Fuse CNN + Contours\n",
    "            fusion_module = ContourFeatureFusion(cnn_feats.shape[1] + 1, cnn_feats.shape[1]).to(device)\n",
    "            fused_features = fusion_module(cnn_feats, contour_maps)\n",
    "\n",
    "            # Step 5-6: Generate & refine masks\n",
    "            masks = batch_process_kmeans_masks_from_features(fused_features)\n",
    "\n",
    "        end_time = time.time()  # ‚è±Ô∏è End timing\n",
    "\n",
    "        batch_time = end_time - start_time\n",
    "        total_time += batch_time\n",
    "        total_images += len(batch_imgs)\n",
    "\n",
    "        final_masks_all.extend(masks)\n",
    "        image_paths_all.extend(paths)\n",
    "\n",
    "    avg_time_ms = (total_time / total_images) * 1000\n",
    "    print(f\"üïí Average Processing Time: {avg_time_ms:.2f} ms/image\")\n",
    "\n",
    "    return final_masks_all, image_paths_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f52731-e91b-47e4-bc56-1c12f70cd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_masks_and_overlay(masks, paths, split_name, save_root=\"Vegetation Masks\"):\n",
    "    \"\"\"\n",
    "    Save binary masks (0/255) to disk and return sample list for visualization.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    save_dir = os.path.join(save_root, split_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    overlay_candidates = []\n",
    "\n",
    "    for mask, path in zip(masks, paths):\n",
    "        # Extract image filename\n",
    "        filename = os.path.basename(path)\n",
    "        filename = os.path.splitext(filename)[0] + \".png\"  # Save all as .png\n",
    "\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "        # Convert mask to uint8: values 0 and 255\n",
    "        mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "        cv2.imwrite(save_path, mask_uint8)\n",
    "\n",
    "        # Save for potential overlay\n",
    "        overlay_candidates.append((path, mask_uint8))\n",
    "\n",
    "    print(f\"‚úÖ Saved {len(masks)} masks to '{save_dir}'\")\n",
    "    return overlay_candidates\n",
    "\n",
    "\n",
    "def show_random_overlay(sample_list, overlay_color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Visualize one overlayed mask on top of original RGB image.\n",
    "    \"\"\"\n",
    "    img_path, mask = random.choice(sample_list)\n",
    "\n",
    "    # Load image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize mask if needed\n",
    "    if mask.shape != img.shape[:2]:\n",
    "        mask = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Apply colored overlay\n",
    "    overlay = img.copy()\n",
    "    overlay[mask == 255] = overlay_color\n",
    "\n",
    "    # Blend original + overlay\n",
    "    blended = cv2.addWeighted(img, 0.4, overlay, 0.6, 0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Overlayed Vegetation Mask\")\n",
    "    plt.imshow(blended)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d8111-af56-47b7-9798-de433f24c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9f7a630e134aeda7734da17a1ddfc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üì¶ Step 7: Batch Inference:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efe942063464da9bf7df3a45fbd1b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4c8c0b44534082982d12e8226aed7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4731571a194097a908c5baaa32865e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344e94d3a2d74cfaa5107f1a875d466e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd9b05d44684f12a5189af195b7160f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adc46984ce64ae688948e4cb81e161c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645ec3233a914427bd34da34f5ea9b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cd1ed1950e4f1fa218cef0f45fe0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ccd400aae2474ea4f42b44bb2c8cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66eb486fd214bfca42ef69b226c428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50945b3618404dce857161aaa6a3a52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b9eb3ea41b4c6d9365728837bd6353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ef5872a6046a1b9ad1c9d61eb05ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6cb2fae5dc4080b449b9a550838d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d98c8d63c164318a89a02c6431fcf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b8afead15f4d37babec18c1da27b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a29e6a7bb804224aa245d30bdd8a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d129a89aa7e7426e9518f0a93fbefa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7b1834532f4c0a8118df1ce01c62e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b80647eb0c34f6dbe46f8066562404d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e1186c680740a8ac3db63caa7a7e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc0ef57fd56458eb427f1a436341dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d757ff87a8e49e4b4b2b77759d907c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40f80e41aa84733aa19ae4ce47d49b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9062ddfeca457492487d3553ef34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954c67bf76bf436282df3d1f5fe57cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc69c04adeb642c9a09682436eb73e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10eaac48c905464f82c057e28f4540c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e4d1db3530457d87316e88817f9364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae6a1ec30cb465990a70ddc07752ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a393963a6c1b44059fccb953c835d2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5110825e3b744c939e03ee2ec9bc0a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc6017154c6425ab6c6f1a7e0c6f761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a17bd09a1bc428480eb0dd65ca0747f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ff00d52f3a4fcdbde388fab28d497b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5715904a2391479a9cb5809c74488a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af3f45c31774ba89a66c34df9f9930e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d074c162fe0642349e006d3f5d07aaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a675e9430f8c47888bff9317a14d1f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb934cb01304b90978986113b9cf509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0059fd2f7bdb461d9e2dabc6f9734fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196d22a8ca034e6d870d750d865e7283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üß† Step 6: Refining Masks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üîÅ Instantiate the feature extractor (Step 3)\n",
    "feature_extractor = HRNetW32FeatureExtractor(device=DEVICE)\n",
    "\n",
    "# üîÑ Run batch inference for all 3 splits\n",
    "train_masks, train_paths = batch_infer_masks(train_loader, feature_extractor, DEVICE)\n",
    "val_masks, val_paths     = batch_infer_masks(val_loader, feature_extractor, DEVICE)\n",
    "test_masks, test_paths   = batch_infer_masks(test_loader, feature_extractor, DEVICE)\n",
    "\n",
    "# üíæ Save masks and prepare overlays (Step 8)\n",
    "train_samples = save_masks_and_overlay(train_masks, train_paths, \"train\")\n",
    "val_samples   = save_masks_and_overlay(val_masks, val_paths, \"val\")\n",
    "test_samples  = save_masks_and_overlay(test_masks, test_paths, \"test\")\n",
    "\n",
    "# üëÄ Show a random overlay from validation set\n",
    "show_random_overlay(val_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad9bd9b-391e-413b-a372-9d861fbe9f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
