{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550fe726-542f-47d2-ab73-2905ae98b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as T\n",
    "import torchvision as TV\n",
    "import torchaudio as TA\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from glob import glob\n",
    "import albumentations as A\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from pathlib import Path\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23d4b15-751e-4e45-ad08-a040f8b3a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.manual_seed(22)\n",
    "np.random.seed(22)\n",
    "random.seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536f24c4-31da-4781-8b6f-03a75276059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- DEVICE -----------------------\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f30aa41-32ab-4d82-8665-74505221a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Paths -----------------------\n",
    "train_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\train_new\"\n",
    "train_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\trainlabel_new\"\n",
    "validation_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\validation_new\"\n",
    "validation_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\validationlabel_new\"\n",
    "test_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\test_new\"\n",
    "test_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\testlabel_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e07beed-1b72-458b-b846-23816cd8bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying Training File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1600/1600 [00:00<00:00, 102641.19it/s]\n",
      "Verifying Validation File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 352/352 [00:00<00:00, 147787.29it/s]\n",
      "Verifying Testing File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1200/1200 [00:00<00:00, 101729.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1600\n",
      "Validation samples: 352\n",
      "Testing samples: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Simple Transform -----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ---------------------- Simplified Dataset Class -----------------------\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SimpleSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, dataset_type=\"Unknown\"):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.dataset_type = dataset_type\n",
    "        self.image_files = sorted(glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.mask_files = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n",
    "        self._verify_file_pairs()\n",
    "        \n",
    "    def _verify_file_pairs(self):\n",
    "        if len(self.image_files) != len(self.mask_files):\n",
    "            raise ValueError(f\"Mismatched counts in {self.dataset_type} dataset: {len(self.image_files)} images vs {len(self.mask_files)} masks\")\n",
    "            \n",
    "        for img_path, mask_path in tqdm(zip(self.image_files, self.mask_files), total=len(self.image_files), desc=f\"Verifying {self.dataset_type} File Pairs üîç\"):\n",
    "            img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            mask_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "            if img_name != mask_name:\n",
    "                raise ValueError(f\"Filename mismatch in {self.dataset_type} dataset: {img_name} vs {mask_name}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.image_files[idx]), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_files[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        \n",
    "        mask = T.from_numpy(mask).long()\n",
    "        \n",
    "        return img, mask, self.image_files[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    masks = torch.stack([item[1] for item in batch])\n",
    "    filenames = [item[2] for item in batch]\n",
    "    return images, masks, filenames\n",
    "\n",
    "# ---------------------- DataLoaders -----------------------\n",
    "train_dataset = SimpleSegmentationDataset(\n",
    "    image_dir=train_images,\n",
    "    mask_dir=train_masks,\n",
    "    transform=transform,\n",
    "    dataset_type=\"Training\"\n",
    ")\n",
    "val_dataset = SimpleSegmentationDataset(\n",
    "    image_dir=validation_images,\n",
    "    mask_dir=validation_masks,\n",
    "    transform=transform,\n",
    "    dataset_type=\"Validation\"\n",
    ")\n",
    "test_dataset = SimpleSegmentationDataset(\n",
    "    image_dir=test_images,\n",
    "    mask_dir=test_masks,\n",
    "    transform=transform,\n",
    "    dataset_type=\"Testing\"\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295ec20-319a-4744-a78d-59878f76264f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [04:27<00:00,  1.49it/s, loss=0.156]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:21<00:00,  4.17it/s, loss=0.164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New best mPA: 95.33% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mPA_model.pth\n",
      "\n",
      "üìä Epoch 1 Summary:\n",
      "Train Loss: 0.3093 | Val Loss: 0.1690\n",
      "Accuracy: 98.90%\n",
      "mPA: 95.33%\n",
      "Crop IoU: 89.61%\n",
      "mIoU: 94.20%\n",
      "Precision: 98.55%\n",
      "Recall: 90.81%\n",
      "F1-Score: 94.52%\n",
      "FNR: 9.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [04:33<00:00,  1.46it/s, loss=0.131]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:20<00:00,  4.38it/s, loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New best mPA: 97.75% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mPA_model.pth\n",
      "\n",
      "üìä Epoch 2 Summary:\n",
      "Train Loss: 0.1446 | Val Loss: 0.1247\n",
      "Accuracy: 99.30%\n",
      "mPA: 97.75%\n",
      "Crop IoU: 93.45%\n",
      "mIoU: 96.33%\n",
      "Precision: 97.44%\n",
      "Recall: 95.80%\n",
      "F1-Score: 96.61%\n",
      "FNR: 4.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [04:36<00:00,  1.45it/s, loss=0.108]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:20<00:00,  4.21it/s, loss=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New best mPA: 98.15% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mPA_model.pth\n",
      "\n",
      "üìä Epoch 3 Summary:\n",
      "Train Loss: 0.1258 | Val Loss: 0.1151\n",
      "Accuracy: 99.39%\n",
      "mPA: 98.15%\n",
      "Crop IoU: 94.33%\n",
      "mIoU: 96.83%\n",
      "Precision: 97.59%\n",
      "Recall: 96.59%\n",
      "F1-Score: 97.08%\n",
      "FNR: 3.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [04:31<00:00,  1.47it/s, loss=0.114]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:19<00:00,  4.50it/s, loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New best mPA: 98.66% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mPA_model.pth\n",
      "\n",
      "üìä Epoch 4 Summary:\n",
      "Train Loss: 0.1132 | Val Loss: 0.1143\n",
      "Accuracy: 99.43%\n",
      "mPA: 98.66%\n",
      "Crop IoU: 94.68%\n",
      "mIoU: 97.02%\n",
      "Precision: 96.86%\n",
      "Recall: 97.68%\n",
      "F1-Score: 97.27%\n",
      "FNR: 2.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [04:28<00:00,  1.49it/s, loss=0.074]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:19<00:00,  4.50it/s, loss=0.0807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New best mPA: 99.08% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mPA_model.pth\n",
      "\n",
      "üìä Epoch 5 Summary:\n",
      "Train Loss: 0.0705 | Val Loss: 0.0819\n",
      "Accuracy: 99.39%\n",
      "mPA: 99.08%\n",
      "Crop IoU: 94.40%\n",
      "mIoU: 96.86%\n",
      "Precision: 95.61%\n",
      "Recall: 98.68%\n",
      "F1-Score: 97.12%\n",
      "FNR: 1.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]:  32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 128/400 [01:23<03:22,  1.34it/s, loss=0.058]"
     ]
    }
   ],
   "source": [
    "# ---------------------- Model -----------------------\n",
    "CUSTOM_SAVE_ROOT = Path(r\"D:\\AAU Internship\\Code\\UNet-Models\")\n",
    "os.makedirs(CUSTOM_SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder=\"efficientnet-b5\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_depth=4,\n",
    "    decoder_use_batchnorm='inplace',\n",
    "    decoder_attention_type='scse',\n",
    "    decoder_channels=[256, 128, 64, 32],\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    "    activation=None,\n",
    "    center=True,\n",
    ").to(device)\n",
    "\n",
    "# ---------------------- Loss Function -----------------------\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=0.75, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def update_hyperparams_by_epoch(self, epoch):\n",
    "        steps = epoch // 5\n",
    "        self.alpha = max(0.4, 0.7 - 0.03*steps)\n",
    "        self.beta = 1 - self.alpha\n",
    "        self.gamma = min(1.5, 0.5 + 0.1*steps)\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        probs = F.softmax(preds, dim=1)\n",
    "        dims = (0, 2, 3)\n",
    "    \n",
    "        TP = T.sum(probs * targets_one_hot, dims)\n",
    "        FP = T.sum(probs * (1 - targets_one_hot), dims)\n",
    "        FN = T.sum((1 - probs) * targets_one_hot, dims)\n",
    "    \n",
    "        Tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        return T.mean((1 - Tversky) ** self.gamma)\n",
    "\n",
    "loss_fn = FocalTverskyLoss().to(device)\n",
    "\n",
    "# ---------------------- Metrics -----------------------\n",
    "def compute_metrics(preds, targets):\n",
    "    with T.no_grad():\n",
    "        pred_labels = T.argmax(preds, dim=1).cpu().numpy().flatten()\n",
    "        targets = targets.cpu().numpy().flatten()\n",
    "        ious = []\n",
    "        for cls in [0, 1]:\n",
    "            intersection = ((pred_labels == cls) & (targets == cls)).sum()\n",
    "            union = ((pred_labels == cls) | (targets == cls)).sum()\n",
    "            ious.append(intersection / (union + 1e-6))\n",
    "        class_acc = []\n",
    "        for cls in [0, 1]:\n",
    "            mask = (targets == cls)\n",
    "            if mask.sum() > 0:\n",
    "                class_acc.append((pred_labels[mask] == cls).mean())\n",
    "        mPA = np.mean(class_acc) * 100\n",
    "        cm = confusion_matrix(targets, pred_labels)\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "        return {\n",
    "            \"Accuracy\": 100 * accuracy_score(targets, pred_labels),\n",
    "            \"mPA\": mPA,\n",
    "            \"Crop IoU\": 100 * ious[1],\n",
    "            \"mIoU\": 100 * np.mean(ious),\n",
    "            \"Precision\": 100 * precision_score(targets, pred_labels, zero_division=0),\n",
    "            \"Recall\": 100 * recall_score(targets, pred_labels, zero_division=0),\n",
    "            \"F1-Score\": 100 * f1_score(targets, pred_labels, zero_division=0),\n",
    "            \"FNR\": 100 * (FN / (FN + TP + 1e-6))\n",
    "        }\n",
    "\n",
    "# ---------------------- Training Setup -----------------------\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "MODEL_PATH = CUSTOM_SAVE_ROOT / \"best_mPA_model.pth\"\n",
    "best_mPA = -1  # Initialize to negative value for maximization\n",
    "PRIMARY_METRIC = \"mPA\"  # Primary metric for model selection\n",
    "\n",
    "# ---------------------- Training & Validation -----------------------\n",
    "def TrainUNet(model, dataloader, loss_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "    loss_fn.update_hyperparams_by_epoch(epoch)\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch} [Train]\")\n",
    "\n",
    "    for batch in loop:\n",
    "        inputs, targets, _ = batch  # Unpack tuple: images, masks, filenames (ignored)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append(outputs.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    metrics = compute_metrics(T.cat(all_preds), T.cat(all_targets))\n",
    "\n",
    "    T.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "\n",
    "def ValidateUNet(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "    loop = tqdm(dataloader, desc=\"Validating\")\n",
    "\n",
    "    with T.no_grad():\n",
    "        for batch in loop:\n",
    "            inputs, targets, _ = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            all_preds.append(outputs.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    metrics = compute_metrics(T.cat(all_preds), T.cat(all_targets))\n",
    "    \n",
    "    T.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss, metrics\n",
    "\n",
    "# ---------------------- Main Training -----------------------\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_metrics = TrainUNet(model, train_dataloader, loss_fn, optimizer, epoch)\n",
    "    val_loss, val_metrics = ValidateUNet(model, val_dataloader, loss_fn)\n",
    "\n",
    "    if val_metrics[PRIMARY_METRIC] > best_mPA:\n",
    "        best_mPA = val_metrics[PRIMARY_METRIC]\n",
    "        T.save(model.state_dict(), str(MODEL_PATH))\n",
    "        print(f\"‚úÖ New best {PRIMARY_METRIC}: {best_mPA:.2f}% | Saved to: {MODEL_PATH}\")\n",
    "\n",
    "    print(f\"\\nüìä Epoch {epoch} Summary:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    for k, v in val_metrics.items():\n",
    "        print(f\"{k}: {v:.2f}%\")\n",
    "\n",
    "    T.cuda.empty_cache()\n",
    "\n",
    "# ---------------------- Final Report -----------------------\n",
    "print(f\"\\nüéØ === Best Model Summary ===\")\n",
    "print(f\"Best {PRIMARY_METRIC}: {best_mPA:.2f}% ‚Üí {MODEL_PATH}\")\n",
    "\n",
    "# ---------------------- Testing -----------------------\n",
    "print(\"\\nüß™ === Testing Best Model ===\")\n",
    "model.load_state_dict(T.load(str(MODEL_PATH)))\n",
    "test_loss, test_metrics = ValidateUNet(model, test_dataloader, loss_fn)\n",
    "print(f\"\\nüìå Best {PRIMARY_METRIC} Model Test Results:\")\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b1e356-704c-45ba-a47a-c63fd52db480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üñºÔ∏è Generating and saving segmentation masks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0e33b99da34df3823546eb01fa8468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing datasets:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68997dd29605466ab2c416c307856e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train batch:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626bcf9e974f4a51a00f14f4f5fd98b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val batch:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d741d2d51b3a4df58e5ca3e883b71e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test batch:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Saved 3152 segmentation masks to D:\\AAU Internship\\Code\\Crop_Masks\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Mask Generation -----------------------\n",
    "MASK_FOLDER_NAME = \"Crop_Masks\"\n",
    "MASK_OUTPUT_DIR = Path.cwd() / MASK_FOLDER_NAME\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (MASK_OUTPUT_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_segmentation_masks(model, train_dataloader, val_dataloader, test_dataloader, model_path, output_dir, device):\n",
    "    model.load_state_dict(T.load(str(model_path)))\n",
    "    model.eval()\n",
    "    dataloader_splits = [\n",
    "        (train_dataloader, 'train'),\n",
    "        (val_dataloader, 'val'),\n",
    "        (test_dataloader, 'test')\n",
    "    ]\n",
    "    mask_counter = 0\n",
    "    \n",
    "    with T.no_grad():\n",
    "        for dataloader, split in tqdm(dataloader_splits, desc=\"Processing datasets\"):\n",
    "            split_dir = output_dir / split\n",
    "            for batch in tqdm(dataloader, desc=f\"Processing {split} batch\", leave=True):\n",
    "                inputs, _, filenames = batch\n",
    "                inputs = inputs.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                outputs = model(inputs)\n",
    "                pred_labels = T.argmax(outputs, dim=1).cpu().numpy()\n",
    "                for i in range(batch_size):\n",
    "                    mask = pred_labels[i]\n",
    "                    mask = (mask * 255).astype(np.uint8)\n",
    "                    image_name = Path(filenames[i]).stem + \".png\"  # Save as .png\n",
    "                    mask_path = str(split_dir / image_name)\n",
    "                    cv2.imwrite(mask_path, mask)  # cv2 automatically writes as PNG with .png extension\n",
    "                    mask_counter += 1\n",
    "    \n",
    "    print(f\"\\nüéâ Saved {mask_counter} segmentation masks to {output_dir}\")\n",
    "\n",
    "print(\"\\nüñºÔ∏è Generating and saving segmentation masks...\")\n",
    "save_segmentation_masks(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    model_path=CUSTOM_SAVE_ROOT / \"best_mPA_model.pth\",\n",
    "    output_dir=MASK_OUTPUT_DIR,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "T.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de43a7ce-6afb-48d8-b6e5-0f0bfe325da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_SAVE_ROOT = Path(r\"D:\\AAU Internship\\Code\\UNet-Models\")\n",
    "os.makedirs(CUSTOM_SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder=\"efficientnet-b5\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_depth=4,\n",
    "    decoder_use_batchnorm='inplace',\n",
    "    decoder_attention_type='scse',\n",
    "    decoder_channels=[256, 128, 64, 32],\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    "    activation=None,\n",
    "    center=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97945c-67c6-4c63-92a5-970a5aa9a82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
