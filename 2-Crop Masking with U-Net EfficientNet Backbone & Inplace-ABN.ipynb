{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550fe726-542f-47d2-ab73-2905ae98b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as T\n",
    "import torchvision as TV\n",
    "import torchaudio as TA\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from glob import glob\n",
    "import albumentations as A\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536f24c4-31da-4781-8b6f-03a75276059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- DEVICE -----------------------\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f30aa41-32ab-4d82-8665-74505221a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Paths -----------------------\n",
    "train_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\train_new\"\n",
    "train_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\trainlabel_new\"\n",
    "validation_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\validation_new\"\n",
    "validation_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\validationlabel_new\"\n",
    "test_images = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\test_new\"\n",
    "test_masks = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\testlabel_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e07beed-1b72-458b-b846-23816cd8bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "Verifying Training File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [00:00<00:00, 87806.65it/s]\n",
      "Verifying Validation File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 87859.74it/s]\n",
      "Verifying Testing File Pairs üîç: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:00<00:00, 53495.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Augmentations -----------------------\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.D4(p=1),\n",
    "    A.ISONoise(color_shift=[0.01, 0.05], intensity=[0.1, 0.5], p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.2], contrast_limit=[-0.2, 0.2], p=0.5),\n",
    "    A.ElasticTransform(alpha=300, sigma=10, interpolation=cv2.INTER_NEAREST, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                       same_dxdy=True, border_mode=cv2.BORDER_CONSTANT, fill=0, fill_mask=0, p=0.5),\n",
    "    A.Resize(512, 384),\n",
    "])\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ---------------------- Dataset Class -----------------------\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, train_transform=None, base_transform=None, dataset_type=\"Unknown\"):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.train_transform = train_transform\n",
    "        self.base_transform = base_transform\n",
    "        self.dataset_type = dataset_type\n",
    "        self.image_files = sorted(glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.mask_files = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n",
    "        self._verify_file_pairs()\n",
    "        \n",
    "    def _verify_file_pairs(self):\n",
    "        if len(self.image_files) != len(self.mask_files):\n",
    "            raise ValueError(f\"Mismatched counts in {self.dataset_type} dataset: {len(self.image_files)} images vs {len(self.mask_files)} masks\")\n",
    "            \n",
    "        for img_path, mask_path in tqdm(zip(self.image_files, self.mask_files), total=len(self.image_files), desc=f\"Verifying {self.dataset_type} File Pairs üîç\"):\n",
    "            img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            mask_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "            if img_name != mask_name:\n",
    "                raise ValueError(f\"Filename mismatch in {self.dataset_type} dataset: {img_name} vs {mask_name}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.image_files[idx]), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.mask_files[idx], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "    \n",
    "        original_img = self.base_transform(img)\n",
    "        original_mask = T.from_numpy(mask).long()\n",
    "    \n",
    "        sample = {\n",
    "            \"original_img\": original_img,\n",
    "            \"original_mask\": original_mask\n",
    "        }\n",
    "    \n",
    "        if self.train_transform:\n",
    "            augmented = self.train_transform(image=img, mask=mask)\n",
    "            aug_img = augmented[\"image\"]\n",
    "            aug_mask = augmented[\"mask\"]\n",
    "    \n",
    "            augmented_img = self.base_transform(aug_img)\n",
    "            augmented_mask = T.from_numpy(aug_mask).long()\n",
    "    \n",
    "            sample[\"augmented_img\"] = augmented_img\n",
    "            sample[\"augmented_mask\"] = augmented_mask\n",
    "        else:\n",
    "            sample[\"augmented_img\"] = original_img\n",
    "            sample[\"augmented_mask\"] = original_mask\n",
    "    \n",
    "        return sample\n",
    "\n",
    "\n",
    "# ---------------------- DataLoaders -----------------------\n",
    "train_dataset = SegmentationDataset(train_images, train_masks, train_transform, base_transform, \"Training\")\n",
    "val_dataset = SegmentationDataset(validation_images, validation_masks, train_transform, base_transform, \"Validation\")\n",
    "test_dataset = SegmentationDataset(test_images, test_masks, train_transform, base_transform, \"Testing\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295ec20-319a-4744-a78d-59878f76264f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [02:39<00:00,  1.25it/s, loss=0.249]\n",
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:17<00:00,  2.57it/s, loss=0.269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New best mPA: 97.22% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mPA_model.pth\n",
      "‚úÖ New best mIoU: 94.26% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_mIoU_model.pth\n",
      "‚úÖ New best Crop IoU: 89.77% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_CropIoU_model.pth\n",
      "‚úÖ New best Accuracy: 98.87% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_Accuracy_model.pth\n",
      "‚úÖ New best F1-Score: 94.61% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_F1-Score_model.pth\n",
      "‚úÖ New best Precision: 94.10% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_Precision_model.pth\n",
      "‚úÖ New best Recall: 95.13% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_Recall_model.pth\n",
      "‚úÖ New best FNR: 4.87% | Saved to: D:\\AAU Internship\\Code\\UNet-Models\\best_FNR_model.pth\n",
      "\n",
      "üìä Epoch 1 Summary:\n",
      "Train Loss: 0.4260 | Val Loss: 0.2536\n",
      "Accuracy: 98.87%\n",
      "mPA: 97.22%\n",
      "Crop IoU: 89.77%\n",
      "mIoU: 94.26%\n",
      "Precision: 94.10%\n",
      "Recall: 95.13%\n",
      "F1-Score: 94.61%\n",
      "FNR: 4.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                          | 39/200 [00:31<02:30,  1.07it/s, loss=0.17]"
     ]
    }
   ],
   "source": [
    "# ---------------------- Model -----------------------\n",
    "CUSTOM_SAVE_ROOT = Path(r\"D:\\AAU Internship\\Code\\UNet-Models\")\n",
    "os.makedirs(CUSTOM_SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder=\"efficientnet-b5\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_depth=4,\n",
    "    decoder_use_batchnorm='inplace',\n",
    "    decoder_attention_type='scse',\n",
    "    decoder_channels=[256, 128, 64, 32],\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    "    activation=None,\n",
    "    center=True,\n",
    ").to(device)\n",
    "\n",
    "# ---------------------- Loss Function -----------------------\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=0.75, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def update_hyperparams_by_epoch(self, epoch):\n",
    "        steps = epoch // 5\n",
    "        self.alpha = max(0.4, 0.7 - 0.03*steps)\n",
    "        self.beta = 1 - self.alpha\n",
    "        self.gamma = min(1.5, 0.5 + 0.1*steps)\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        probs = F.softmax(preds, dim=1)  # ‚Üê FIXED: convert logits to probabilities\n",
    "        dims = (0, 2, 3)\n",
    "    \n",
    "        TP = T.sum(probs * targets_one_hot, dims)\n",
    "        FP = T.sum(probs * (1 - targets_one_hot), dims)\n",
    "        FN = T.sum((1 - probs) * targets_one_hot, dims)\n",
    "    \n",
    "        Tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        # clamp is not really needed unless you're debugging, but it shouldn't break\n",
    "        # Tversky = T.clamp(Tversky, max=1.0)\n",
    "    \n",
    "        return T.mean((1 - Tversky) ** self.gamma)\n",
    "\n",
    "loss_fn = FocalTverskyLoss().to(device)\n",
    "\n",
    "# ---------------------- Metrics -----------------------\n",
    "def compute_metrics(preds, targets):\n",
    "    with T.no_grad():\n",
    "        pred_labels = T.argmax(preds, dim=1).cpu().numpy().flatten()\n",
    "        targets = targets.cpu().numpy().flatten()\n",
    "        ious = []\n",
    "        for cls in [0, 1]:\n",
    "            intersection = ((pred_labels == cls) & (targets == cls)).sum()\n",
    "            union = ((pred_labels == cls) | (targets == cls)).sum()\n",
    "            ious.append(intersection / (union + 1e-6))\n",
    "        class_acc = []\n",
    "        for cls in [0, 1]:\n",
    "            mask = (targets == cls)\n",
    "            if mask.sum() > 0:\n",
    "                class_acc.append((pred_labels[mask] == cls).mean())\n",
    "        mPA = np.mean(class_acc) * 100\n",
    "        cm = confusion_matrix(targets, pred_labels)\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "        return {\n",
    "            \"Accuracy\": 100 * accuracy_score(targets, pred_labels),\n",
    "            \"mPA\": mPA,\n",
    "            \"Crop IoU\": 100 * ious[1],\n",
    "            \"mIoU\": 100 * np.mean(ious),\n",
    "            \"Precision\": 100 * precision_score(targets, pred_labels, zero_division=0),\n",
    "            \"Recall\": 100 * recall_score(targets, pred_labels, zero_division=0),\n",
    "            \"F1-Score\": 100 * f1_score(targets, pred_labels, zero_division=0),\n",
    "            \"FNR\": 100 * (FN / (FN + TP + 1e-6))\n",
    "        }\n",
    "\n",
    "# ---------------------- Training Setup -----------------------\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "MODEL_PATHS = {name: CUSTOM_SAVE_ROOT / f\"best_{name.replace(' ', '')}_model.pth\" for name in [\n",
    "    \"mPA\", \"mIoU\", \"Crop IoU\", \"Accuracy\", \"F1-Score\", \"Precision\", \"Recall\", \"FNR\"\n",
    "]}\n",
    "best_metrics = {k: {\"value\": -1 if k != \"FNR\" else float('inf'), \"path\": v} for k, v in MODEL_PATHS.items()}\n",
    "\n",
    "# ---------------------- Training & Validation -----------------------\n",
    "def TrainUNet(model, dataloader, loss_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "    loss_fn.update_hyperparams_by_epoch(epoch)\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch} [Train]\")\n",
    "\n",
    "    for batch in loop:\n",
    "        inputs = batch['augmented_img'].to(device)\n",
    "        targets = batch['augmented_mask'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append(outputs.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    metrics = compute_metrics(T.cat(all_preds), T.cat(all_targets))\n",
    "\n",
    "    T.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "\n",
    "def ValidateUNet(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "    loop = tqdm(dataloader, desc=\"Validating\")\n",
    "\n",
    "    with T.no_grad():\n",
    "        for batch in loop:\n",
    "            inputs = batch['original_img'].to(device)\n",
    "            targets = batch['original_mask'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            all_preds.append(outputs.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    metrics = compute_metrics(T.cat(all_preds), T.cat(all_targets))\n",
    "    \n",
    "    T.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss, metrics\n",
    "\n",
    "# ---------------------- Main Training -----------------------\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_metrics = TrainUNet(model, train_dataloader, loss_fn, optimizer, epoch)\n",
    "    val_loss, val_metrics = ValidateUNet(model, val_dataloader, loss_fn)\n",
    "\n",
    "    T.cuda.empty_cache()\n",
    "\n",
    "    for metric_name in best_metrics.keys():\n",
    "        current_value = val_metrics[metric_name]\n",
    "        is_better = current_value > best_metrics[metric_name][\"value\"] if metric_name != \"FNR\" else current_value < best_metrics[metric_name][\"value\"]\n",
    "        if is_better:\n",
    "            best_metrics[metric_name][\"value\"] = current_value\n",
    "            T.save(model.state_dict(), str(best_metrics[metric_name][\"path\"]))\n",
    "            print(f\"‚úÖ New best {metric_name}: {current_value:.2f}% | Saved to: {best_metrics[metric_name]['path']}\")\n",
    "\n",
    "    print(f\"\\nüìä Epoch {epoch} Summary:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    for k, v in val_metrics.items():\n",
    "        print(f\"{k}: {v:.2f}%\")\n",
    "\n",
    "\n",
    "# ---------------------- Final Report -----------------------\n",
    "print(\"\\nüéØ === Best Models Summary ===\")\n",
    "for metric_name, data in best_metrics.items():\n",
    "    print(f\"{metric_name}: {data['value']:.2f}% ‚Üí {data['path']}\")\n",
    "\n",
    "# ---------------------- Testing -----------------------\n",
    "print(\"\\nüß™ === Testing Saved Models ===\")\n",
    "for metric_name, data in tqdm(best_metrics.items(), desc=\"Testing Models\"):\n",
    "    model.load_state_dict(T.load(str(data[\"path\"])))\n",
    "    test_loss, test_metrics = ValidateUNet(model, test_dataloader, loss_fn)\n",
    "    print(f\"\\nüìå {metric_name} Model Test Results:\")\n",
    "    for k, v in test_metrics.items():\n",
    "        print(f\"{k}: {v:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1e356-704c-45ba-a47a-c63fd52db480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
