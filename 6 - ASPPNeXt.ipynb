{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5262a4-3066-4b54-b6f4-ab733ed9233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ab70a1c-1825-4e74-81b4-23fceb8604a0",
   "metadata": {},
   "source": [
    "--------------------xX ASPPNeXt Architecture Xx--------------------\n",
    "\n",
    "             RGB Input          Depth Input\n",
    "                │                   │\n",
    "       ┌────────▼────────┐ ┌────────▼────────┐\n",
    "       │ Hybrid ConvNeXt │ │ Hybrid ConvNeXt │\n",
    "       │ Block ×4 (with  │ │ Block ×4 (with  │\n",
    "       │  VWA + GhostMLP)│ │  VWA + GhostMLP)│\n",
    "       └────────┬────────┘ └────────┬────────┘\n",
    "                │                   │\n",
    "       ┌────────▼────────┐ ┌────────▼────────┐\n",
    "       │ Pre-DAAF        │ │ Pre-DAAF        │\n",
    "       │ GhostModule     │ │ GhostModule     │\n",
    "       └────────┬────────┘ └────────┬────────┘\n",
    "                │                   │\n",
    "                └──────► DAAF ◄─────┘\n",
    "                          │\n",
    "                ┌─────────▼─────────┐\n",
    "                │ Post-DAAF         │\n",
    "                │ GhostModule       │\n",
    "                └─────────┬─────────┘\n",
    "                          │\n",
    "             ┌────────────▼────────────┐\n",
    "             │ Decoder Stage 1         │\n",
    "             │ GhostASPPFELAN          │\n",
    "             │ CoordAttention          │\n",
    "             │ DySample (×2)           │\n",
    "             │ +Skip Connections (E4)  │\n",
    "             └────────────┬────────────┘\n",
    "                          │\n",
    "             ┌────────────▼────────────┐\n",
    "             │ Decoder Stage 2         │\n",
    "             │ GhostASPPFELAN          │\n",
    "             │ CoordAttention          │\n",
    "             │ DySample (×2)           │\n",
    "             │ +Skip Connections (E3)  │\n",
    "             └────────────┬────────────┘\n",
    "                          │\n",
    "             ┌────────────▼────────────┐\n",
    "             │ Decoder Stage 3         │\n",
    "             │ GhostASPPFELAN          │\n",
    "             │ CoordAttention          │\n",
    "             │ DySample (×2)           │\n",
    "             │ +Skip Connections (E2)  │\n",
    "             └────────────┬────────────┘\n",
    "                          │\n",
    "                   Final 1×1 Conv\n",
    "                          ↓\n",
    "                     Output Map\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c133a51c-fd32-48e9-afa1-8098e6d1e257",
   "metadata": {},
   "source": [
    "--------------------xX GhostModule Xx--------------------\n",
    "\n",
    "Input: (B, C_in, H, W)\n",
    "  ↓\n",
    "Primary Features: \n",
    "  - 1×1 Conv → C_mid = C_out // ratio\n",
    "  ↓\n",
    "Ghost Features:\n",
    "  - Depthwise Conv (or cheap linear ops) on C_mid\n",
    "  ↓\n",
    "Concatenate Primary + Ghost → C_out\n",
    "  ↓\n",
    "BatchNorm (optional)\n",
    "  ↓\n",
    "Output: (B, C_out, H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9544a6f3-e3fd-4213-bf8e-4f1c86f66f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFCAttention(nn.Module):\n",
    "    \"\"\"Depthwise-Fully-Connected Attention from GhostNetV2\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dfc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # Global Avg Pool\n",
    "            nn.Conv2d(channels, channels, kernel_size=1, bias=False),  # FC1\n",
    "            nn.Hardswish(inplace=True),  # Replaced ReLU with Hardswish\n",
    "            nn.Conv2d(channels, channels, kernel_size=1, bias=False),  # FC2\n",
    "            nn.Sigmoid()  # Sigmoid for attention weights\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.dfc(x)  # Channel-wise multiplication\n",
    "\n",
    "class GhostModuleV2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        ratio: int = 2,\n",
    "        kernel_size: int = 1,\n",
    "        dw_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        use_attn: bool = True  # Enable/disable DFC Attention\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        init_channels = math.ceil(out_channels / ratio)\n",
    "        new_channels = init_channels * (ratio - 1)\n",
    "\n",
    "        # Primary 1×1 convolution (intrinsic features)\n",
    "        self.primary_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, init_channels,\n",
    "                kernel_size=kernel_size, stride=stride,\n",
    "                padding=kernel_size // 2, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(init_channels),\n",
    "            nn.Hardswish(inplace=True),  # ReLU → Hardswish (V2 change)\n",
    "        )\n",
    "\n",
    "        # Cheap depthwise convolution (ghost features)\n",
    "        self.cheap_operation = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                init_channels, new_channels,\n",
    "                kernel_size=dw_size, stride=1,\n",
    "                padding=dw_size // 2,\n",
    "                groups=init_channels, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(new_channels),\n",
    "            nn.Hardswish(inplace=True),  # ReLU → Hardswish (V2 change)\n",
    "        )\n",
    "\n",
    "        # DFC Attention (V2 addition)\n",
    "        self.use_attn = use_attn\n",
    "        if use_attn:\n",
    "            self.attn = DFCAttention(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Intrinsic + Ghost features\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        out = T.cat([x1, x2], dim=1)\n",
    "        out = out[:, :self.out_channels, :, :]  # Trim to out_channels\n",
    "\n",
    "        # Apply DFC Attention (V2)\n",
    "        if self.use_attn:\n",
    "            out = self.attn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59c0e33b-905a-4c8c-a202-e860c4ae83a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "--------------------xX Hybrid ConvNeXt Block Xx--------------------\n",
    "\n",
    "Input: X ∈ ℝ^(B×C×H×W)\n",
    "  ↓\n",
    "7×7 DepthwiseConv\n",
    "  ↓\n",
    "Permute → ℝ^(B×H×W×C)\n",
    "  ↓\n",
    "LayerNorm\n",
    "  ↓\n",
    "Varying Window Attention:\n",
    "  • Query window: P×P fixed\n",
    "  • Context window: (R×P)×(R×P)\n",
    "  • MHSA with zero extra cost\n",
    "  ↓\n",
    "Residual Add\n",
    "  ↓\n",
    "LayerNorm\n",
    "  ↓\n",
    "Ghost MLP:\n",
    "  • GhostConv(1×1): C→4C → GELU\n",
    "  • GhostConv(1×1): 4C→C\n",
    "  ↓\n",
    "Residual Add\n",
    "  ↓\n",
    "Permute back → ℝ^(B×C×H×W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632c4c0f-bf1b-4412-ae5d-1f4f0c5907a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaryingWindowAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads, window_size, context_ratio=2):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.context_ratio = context_ratio\n",
    "        \n",
    "        # Projections for Q/K/V\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        \n",
    "        # Output projection\n",
    "        self.to_out = nn.Linear(dim, dim, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        H = W = int(N ** 0.5)\n",
    "        P = self.window_size\n",
    "        R = self.context_ratio\n",
    "        \n",
    "        # Reshape to (B, H, W, C)\n",
    "        x_spatial = x.view(B, H, W, C)\n",
    "        \n",
    "        # 1. Create P×P query windows\n",
    "        q_windows = x_spatial.unfold(1, P, P).unfold(2, P, P)\n",
    "        q_windows = q_windows.contiguous().view(B, -1, P*P, C)\n",
    "        \n",
    "        # 2. Create (R*P)×(R*P) context windows\n",
    "        pad = (R * P - P) // 2\n",
    "        x_pad = F.pad(x_spatial, (0, 0, pad, pad, pad, pad))\n",
    "        ctx_windows = x_pad.unfold(1, R*P, P).unfold(2, R*P, P)\n",
    "        ctx_windows = ctx_windows.contiguous().view(B, -1, (R*P)**2, C)\n",
    "        \n",
    "        # 3. Concatenate queries and context\n",
    "        seq = T.cat([q_windows, ctx_windows], dim=2)\n",
    "        \n",
    "        # 4. Compute Q, K, V\n",
    "        qkv = self.to_qkv(seq)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)  # Split into q, k, v\n",
    "        \n",
    "        # 5. Scaled dot-product attention\n",
    "        attn = (q @ k.transpose(-2, -1)) * (C ** -0.5)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        out = attn @ v\n",
    "        \n",
    "        # 6. Keep only query window outputs\n",
    "        out = out[:, :, :P*P, :]\n",
    "        \n",
    "        # 7. Reconstruct spatial layout\n",
    "        out = out.view(B, H//P, W//P, P, P, C)\n",
    "        out = out.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, C)\n",
    "        out = out.view(B, N, C)\n",
    "        \n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class GhostMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Ghost MLP with two GhostModuleV2 layers and GELU activation.\n",
    "    Expands C→4C then projects back 4C→C.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, mlp_ratio=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = dim * mlp_ratio\n",
    "        self.fc1 = GhostModuleV2(dim, hidden_dim, use_attn=False)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = GhostModuleV2(hidden_dim, dim, use_attn=False)\n",
    "\n",
    "    def forward(self, x: T.Tensor) -> T.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, N, C)\n",
    "        returns: (B, N, C)\n",
    "        \"\"\"\n",
    "        B, N, C = x.shape\n",
    "        # reshape to (B, C, H, W) for GhostModuleV2, then back\n",
    "        H = W = int(N ** 0.5)\n",
    "        x_spatial = x.view(B, H, W, C).permute(0,3,1,2)\n",
    "        x_spatial = self.act(self.fc1(x_spatial))\n",
    "        x_spatial = self.fc2(x_spatial)\n",
    "        x_flat = x_spatial.permute(0,2,3,1).view(B, N, C)\n",
    "        return x_flat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3b707c-efb0-47c6-85f2-f7818a31dcde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mHybridConvNeXtBlock\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModule\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mcontext_ratio\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;250;43m        \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[33;43;03m        Args:\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[33;43;03m          dim: number of input channels\u001b[39;49;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;43;03m          mlp_ratio: expansion factor for Ghost MLP\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[33;43;03m        \"\"\"\u001b[39;49;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mHybridConvNeXtBlock\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# 4) Ghost MLP expands (2C→8C) then projects back (8C→2C)\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m.mlp = GhostMLP(dim * \u001b[32m2\u001b[39m, mlp_ratio)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[43mtorch\u001b[49m.Tensor) -> torch.Tensor:\n\u001b[32m     43\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    x: (B, C, H, W)\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m    returns: (B, 2C, H/2, W/2)\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# 0. Ghost downsample\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class HybridConvNeXtBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 num_heads: int,\n",
    "                 window_size: int,\n",
    "                 context_ratio: int = 2,\n",
    "                 mlp_ratio: int = 4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          dim: number of input channels\n",
    "          num_heads: heads for attention\n",
    "          window_size: P (query window)\n",
    "          context_ratio: R (context window = R·P)\n",
    "          mlp_ratio: expansion factor for Ghost MLP\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 0) GhostModule downsampling: dim→2*dim, stride=2\n",
    "        self.down = GhostModuleV2(\n",
    "            in_channels=dim,\n",
    "            out_channels=dim * 2,\n",
    "            ratio=2,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            use_attn=False\n",
    "        )\n",
    "        # 1) 7×7 depthwise convolution on downsampled features\n",
    "        self.dwconv = nn.Conv2d(dim * 2, dim * 2, kernel_size=7,\n",
    "                                padding=3, groups=dim * 2, bias=False)\n",
    "        # 2) LayerNorms for sequence data\n",
    "        self.norm1 = nn.LayerNorm(dim * 2)\n",
    "        self.norm2 = nn.LayerNorm(dim * 2)\n",
    "        # 3) Varying Window Attention\n",
    "        self.attn = VaryingWindowAttention(\n",
    "            dim=dim * 2,\n",
    "            num_heads=num_heads,\n",
    "            window_size=window_size,\n",
    "            context_ratio=context_ratio\n",
    "        )\n",
    "        # 4) Ghost MLP expands (2C→8C) then projects back (8C→2C)\n",
    "        self.mlp = GhostMLP(dim * 2, mlp_ratio)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, C, H, W)\n",
    "        returns: (B, 2C, H/2, W/2)\n",
    "        \"\"\"\n",
    "        # 0. Ghost downsample\n",
    "        x = self.down(x)  # → (B, 2C, H/2, W/2)\n",
    "\n",
    "        # 1. Depthwise conv\n",
    "        x = self.dwconv(x)  # (B, 2C, H/2, W/2)\n",
    "\n",
    "        # 2. Flatten to sequence for attention: (B, N, 2C)\n",
    "        B, C2, H2, W2 = x.shape\n",
    "        x_seq = x.permute(0, 2, 3, 1).reshape(B, H2*W2, C2)\n",
    "\n",
    "        # 3. Attention + residual\n",
    "        x_seq = x_seq + self.attn(self.norm1(x_seq))\n",
    "\n",
    "        # 4. MLP + residual\n",
    "        x_seq = x_seq + self.mlp(self.norm2(x_seq))\n",
    "\n",
    "        # 5. Reshape back to (B, 2C, H/2, W/2)\n",
    "        x_out = x_seq.view(B, H2, W2, C2).permute(0, 3, 1, 2)\n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e060b4ec-ec2d-4178-a5a0-8fc57be6244c",
   "metadata": {},
   "source": [
    "--------------------xX DAAF Block with GhostModule Integrations Xx--------------------\n",
    "\n",
    "Inputs:\n",
    "  f_rgb_preGhost ∈ ℝ^(B×C×H×W)\n",
    "  f_depth_preGhost ∈ ℝ^(B×C×H×W)\n",
    "\n",
    "1. Local Branch (RDSCB + LIA)\n",
    "   ┌────────────────────────────────────┐\n",
    "   │ RDSCB (n∈{1,3,5,7}):               │\n",
    "   │   For each n: GhostConv(n×n)       │\n",
    "   │   LeakyReLU                        │\n",
    "   │ Concatenate → GhostConv(1×1)       │\n",
    "   └────────────────────────────────────┘\n",
    "       ↓\n",
    "   LIA: Conv1D pooling → GhostConv(1×1)\n",
    "\n",
    "2. Global Branch (ITB)\n",
    "   ┌────────────────────────────────────┐\n",
    "   │ Interactive Self-Attention (ISA)   │\n",
    "   │   Cross-modal MSA on (f_rgb, f_d)  │\n",
    "   │ Residual Add → LayerNorm           │\n",
    "   │ GhostConv FFN:                     │\n",
    "   │   • GhostConv(1×1): C→4C           │\n",
    "   │   • GELU                           │\n",
    "   │   • GhostConv(1×1): 4C→C           │\n",
    "   │ Residual Add                       │\n",
    "   └────────────────────────────────────┘\n",
    "\n",
    "3. Fusion and Reconstruction\n",
    "   ┌──────────────────────────────────────────┐\n",
    "   │ Concat(local, global_rgb, global_depth)  │\n",
    "   │ GhostConv(3×3) → LeakyReLU               │\n",
    "   │ (This is the “Global Fusion” Conv)       │\n",
    "   └──────────────────────────────────────────┘\n",
    "       ↓\n",
    "   Reconstruction Head:\n",
    "   ┌────────────────────────────────────┐\n",
    "   │ GhostConv(3×3) → LeakyReLU         │\n",
    "   │ GhostConv(3×3) → LeakyReLU         │\n",
    "   │ GhostConv(3×3) → LeakyReLU         │\n",
    "   └────────────────────────────────────┘\n",
    "       ↓\n",
    "   Output: f_fused ∈ ℝ^(B×C×H×W)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4a95455-17d8-4fa5-b1d1-66c58ed40f57",
   "metadata": {},
   "source": [
    "The decoder block at each stage of ASPPNeXt with skip-connections, GhostASPPFELAN, CoordAttention and DySample executes in exactly this order:\n",
    "\n",
    "Gather Inputs\n",
    "– If Stage 1: take the Post-DAAF fused feature map\n",
    "– Otherwise: take the upsampled output from the previous decoder stage\n",
    "– Also fetch the skip feature from the corresponding encoder block (E₄→Stage 1, E₃→Stage 2, E₂→Stage 3)\n",
    "\n",
    "Fuse Skip Connection\n",
    "– Concatenate along channels:\n",
    "input ⊕ skip → F₀ (shape: B×(2C)×H×W)\n",
    "\n",
    "GhostASPPFELAN\n",
    "a. Branch 1: GhostConv 1×1 → LeakyReLU\n",
    "b. Branch 2: GhostConv 3×3, dilation=2 → LeakyReLU\n",
    "c. Branch 3: GhostConv 3×3, dilation=4 → LeakyReLU\n",
    "d. Concatenate branches (B×3C_out×H×W) → GhostConv 1×1 fusion → LeakyReLU\n",
    "→ Output F₁ (B×C_out×H×W)\n",
    "\n",
    "CoordAttention\n",
    "a. Pool along H → z_h (B×C×1×W)\n",
    "b. Pool along W → z_w (B×C×H×1)\n",
    "c. Concat(z_h, z_w) → GhostConv(1×1,C→C/r) → LeakyReLU → split into t_h, t_w\n",
    "d. t_h → GhostConv(1×1,C/r→C) → sigmoid → attn_h (B×C×1×W)\n",
    "e. t_w → GhostConv(1×1,C/r→C) → sigmoid → attn_w (B×C×H×1)\n",
    "f. Multiply: F₂ = F₁ × attn_h × attn_w\n",
    "\n",
    "DySample Upsampling (×2)\n",
    "– Optionally pre-process with GhostConv(1×1)\n",
    "– Apply content-aware DySample to F₂ → F₃ (B×C×2H×2W)\n",
    "\n",
    "Pass to Next Stage or Final\n",
    "– F₃ is fed as input to the next decoder stage (or into the final 1×1 conv at the end of Stage 3)\n",
    "\n",
    "Summary of per-stage flow\n",
    "Input + Skip → GhostASPPFELAN → CoordAttention → DySample → Next stage."
   ]
  },
  {
   "cell_type": "raw",
   "id": "467fb663-315e-4b3a-90e6-ed035184a557",
   "metadata": {},
   "source": [
    "--------------------xX Ghost ASPPFELAN Block Xx--------------------\n",
    "\n",
    "Input: X ∈ ℝ^(B×C_in×H×W)\n",
    "  ↓\n",
    "Branch 1: GhostConv(1×1) → LeakyReLU\n",
    "Branch 2: GhostConv(3×3, dilation=2) → LeakyReLU\n",
    "Branch 3: GhostConv(3×3, dilation=4) → LeakyReLU\n",
    "  ↓\n",
    "Concat(branch1,2,3) ∈ ℝ^(B×3C_out×H×W)\n",
    "  ↓\n",
    "GhostConv(1×1) → LeakyReLU\n",
    "  ↓\n",
    "Output: Y ∈ ℝ^(B×C_out×H×W)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d717db5-a2b0-47fd-91e4-3f678caedb7e",
   "metadata": {},
   "source": [
    "--------------------xX CoordAttention Block Xx--------------------\n",
    "\n",
    "Input: X ∈ ℝ^(B×C×H×W)\n",
    "  ↓\n",
    "1. Pool along H: z_h ∈ ℝ^(B×C×1×W)\n",
    "2. Pool along W: z_w ∈ ℝ^(B×C×H×1)\n",
    "  ↓\n",
    "Concat(z_h, z_w) → GhostConv(1×1, C→C/r) → LeakyReLU\n",
    "  ↓\n",
    "Split into t_h, t_w channels\n",
    "  ↓\n",
    "t_h → GhostConv(1×1, C/r→C) → sigmoid → attn_h ∈ ℝ^(B×C×1×W)\n",
    "t_w → GhostConv(1×1, C/r→C) → sigmoid → attn_w ∈ ℝ^(B×C×H×1)\n",
    "  ↓\n",
    "Output: X' = X × attn_h × attn_w\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "813b60a6-67c5-461d-8120-201c989d29eb",
   "metadata": {},
   "source": [
    "--------------------xX DySample Upsampling Xx--------------------\n",
    "\n",
    "Input: X ∈ ℝ^(B×C×H×W)\n",
    "  ↓\n",
    "1. Feature Transformation: GhostConv(1×1)  # Optional\n",
    "2. DySample Operation:\n",
    "   - Dynamic kernel prediction based on local context\n",
    "   - Content-aware upsampling (×2 scale)\n",
    "  ↓\n",
    "Output: X_up ∈ ℝ^(B×C×2H×2W)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
