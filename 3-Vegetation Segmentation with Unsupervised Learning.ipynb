{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1870a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce338520-9012-4bd1-9648-20b57e266a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cuda\n",
      "üì¶ Loaded batch: torch.Size([4, 3, 384, 512]) on cuda:0\n",
      "üñºÔ∏è First image: D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\\train_new\\1_image.jpg\n"
     ]
    }
   ],
   "source": [
    "# üìÅ Set your base image directory\n",
    "BASE_PATH = r\"D:\\AAU Internship\\Code\\CWF-788\\IMAGE512x384\"\n",
    "DEVICE = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {DEVICE}\")\n",
    "\n",
    "# üì¶ Dataset class\n",
    "class VegetationDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.image_paths = sorted(\n",
    "            glob(os.path.join(folder_path, \"*.jpg\")) + glob(os.path.join(folder_path, \"*.png\")),\n",
    "            key=lambda x: [int(t) if t.isdigit() else t for t in re.split(r'(\\d+)', x)]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = cv2.imread(img_path) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "        img = cv2.resize(img, (512, 384), interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img_tensor = T.from_numpy(img).permute(2, 0, 1)\n",
    "\n",
    "        return img_tensor.to(DEVICE), img_path\n",
    "\n",
    "def get_loader(folder_path, batch_size=4):\n",
    "    dataset = VegetationDataset(folder_path)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "train_path = os.path.join(BASE_PATH, \"train_new\")\n",
    "val_path   = os.path.join(BASE_PATH, \"validation_new\")\n",
    "test_path  = os.path.join(BASE_PATH, \"test_new\")\n",
    "train_loader = get_loader(train_path)\n",
    "val_loader   = get_loader(val_path)\n",
    "test_loader  = get_loader(test_path)\n",
    "\n",
    "for batch_imgs, batch_paths in train_loader:\n",
    "    print(f\"üì¶ Loaded batch: {batch_imgs.shape} on {batch_imgs.device}\")\n",
    "    print(f\"üñºÔ∏è First image: {batch_paths[0]}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0dbb6c-19c3-4a54-92ee-de2535a59b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vegetation_indices(batch_imgs):\n",
    "    \"\"\"\n",
    "    Compute 6 vegetation indices from a batch of RGB images.\n",
    "    Input:  batch_imgs [B, 3, H, W], float32 in range [0, 1]\n",
    "    Output: indices_tensor [B, 6, H, W]\n",
    "    \"\"\"\n",
    "\n",
    "    R = batch_imgs[:, 0, :, :]\n",
    "    G = batch_imgs[:, 1, :, :]\n",
    "    B = batch_imgs[:, 2, :, :]\n",
    "\n",
    "    eps = 1e-6  # to prevent division by zero\n",
    "\n",
    "    # 1. ExG = 2G - R - B\n",
    "    ExG = 2 * G - R - B\n",
    "\n",
    "    # 2. ExR = 1.4R - G\n",
    "    ExR = 1.4 * R - G\n",
    "\n",
    "    # 3. CIVE = 0.441R - 0.811G + 0.385B + 18.787\n",
    "    CIVE = 0.441 * R - 0.811 * G + 0.385 * B + 18.787\n",
    "\n",
    "    # 4. VEG = G / (R^0.667 * B^0.333 + eps)\n",
    "    VEG = G / ((R**0.667) * (B**0.333) + eps)\n",
    "\n",
    "    # 5. NDI = (G - R) / (G + R + eps)\n",
    "    NDI = (G - R) / (G + R + eps)\n",
    "\n",
    "    # 6. GLI = (2G - R - B) / (2G + R + B + eps)\n",
    "    GLI = (2 * G - R - B) / (2 * G + R + B + eps)\n",
    "\n",
    "    # Stack all into a single tensor [B, 6, H, W]\n",
    "    indices = T.stack([ExG, ExR, CIVE, VEG, NDI, GLI], dim=1)\n",
    "\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd61f9c-4719-4d39-803c-06e777605169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pca_on_sample(indices_tensor, n_components=1, sample_size=100):\n",
    "    \"\"\"\n",
    "    indices_tensor: [B, 6, H, W]\n",
    "    \"\"\"\n",
    "    B, C, H, W = indices_tensor.shape\n",
    "    reshaped = indices_tensor.permute(0, 2, 3, 1).reshape(-1, C)  # [B*H*W, 6]\n",
    "    \n",
    "    # Sample randomly to limit fitting time\n",
    "    sample = reshaped[T.randperm(reshaped.shape[0])[:sample_size * H]]\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(sample.cpu().numpy())\n",
    "    return pca\n",
    "\n",
    "# 2Ô∏è‚É£ Apply PCA to full batch\n",
    "def apply_pca_to_batch(indices_tensor, pca):\n",
    "    \"\"\"\n",
    "    indices_tensor: [B, 6, H, W]\n",
    "    Returns: [B, 1, H, W] (PCA projected grayscale)\n",
    "    \"\"\"\n",
    "    B, C, H, W = indices_tensor.shape\n",
    "    reshaped = indices_tensor.permute(0, 2, 3, 1).reshape(-1, C)  # [B*H*W, 6]\n",
    "\n",
    "    projected = pca.transform(reshaped.cpu().numpy())  # [B*H*W, 1]\n",
    "    out = T.tensor(projected, dtype=T.float32).reshape(B, H, W)\n",
    "    return out.unsqueeze(1).to(indices_tensor.device)  # [B, 1, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056baae3-2714-40bb-ad3d-f2c2829d1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_multi_otsu(pca_tensor, n_classes=2):\n",
    "    \"\"\"\n",
    "    Input: pca_tensor [B, 1, H, W] (float32, device)\n",
    "    Output: masks [B, H, W] (uint8 binary mask)\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    pca_np = pca_tensor.squeeze(1).cpu().numpy()  # [B, H, W]\n",
    "\n",
    "    for img in pca_np:\n",
    "        thresholds = threshold_multiotsu(img, classes=n_classes)\n",
    "        mask = (img > thresholds[0]).astype(np.uint8)  # binary segmentation\n",
    "        masks.append(mask)\n",
    "\n",
    "    return masks  # list of [H, W] binary masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b865fec1-1485-4260-9c9e-0b0ed8a114dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_masks_with_morphops(mask_list, apply_opening=True, apply_closing=True, dilate=False):\n",
    "    \"\"\"\n",
    "    Refine a list of binary masks using Morphological Operations.\n",
    "    Input: list of [H, W] uint8 masks (0 and 1)\n",
    "    Output: list of refined [H, W] masks\n",
    "    \"\"\"\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    refined = []\n",
    "\n",
    "    for mask in mask_list:\n",
    "        mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "\n",
    "        if apply_opening:\n",
    "            mask_uint8 = cv2.morphologyEx(mask_uint8, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        if apply_closing:\n",
    "            mask_uint8 = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        if dilate:\n",
    "            mask_uint8 = cv2.dilate(mask_uint8, kernel, iterations=1)\n",
    "\n",
    "        refined.append(mask_uint8 // 255)  # Normalize back to 0 or 1\n",
    "\n",
    "    return refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94656738-b32c-4b04-8200-01f1a62d1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vegetation_masks(masks, paths, save_root=\"Vegetation_Masks\"):\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "    for mask, img_path in zip(masks, paths):\n",
    "        # Extract base filename\n",
    "        base_filename = os.path.splitext(os.path.basename(img_path))[0] + \".png\"\n",
    "\n",
    "        # Determine subfolder name from input path\n",
    "        if \"train_new\" in img_path:\n",
    "            subfolder = \"train\"\n",
    "        elif \"validation_new\" in img_path:\n",
    "            subfolder = \"val\"\n",
    "        elif \"test_new\" in img_path:\n",
    "            subfolder = \"test\"\n",
    "        else:\n",
    "            raise ValueError(f\"‚ùå Cannot determine subfolder for: {img_path}\")\n",
    "\n",
    "        # Create subfolder path\n",
    "        save_dir = os.path.join(save_root, subfolder)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Convert mask to 0-255 grayscale\n",
    "        grayscale_mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "        # Save the mask\n",
    "        save_path = os.path.join(save_dir, base_filename)\n",
    "        cv2.imwrite(save_path, grayscale_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541a3e4a-e66d-4b1c-a784-dedf113c7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vegetation_masking_pipeline(dataloader, set_name):\n",
    "    \"\"\"\n",
    "    set_name: one of [\"train\", \"val\", \"test\"]\n",
    "    Returns:\n",
    "        total_images (int), total_time (float in seconds)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüöÄ Starting vegetation masking for {set_name} set...\")\n",
    "    total_images = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_imgs, batch_paths in tqdm(dataloader, desc=f\"üå± Processing {set_name}\"):\n",
    "        total_images += len(batch_imgs)\n",
    "\n",
    "        # Step 1: Compute vegetation indices\n",
    "        veg_indices = compute_vegetation_indices(batch_imgs)\n",
    "\n",
    "        # Step 2: PCA (fit on sample)\n",
    "        pca_model = fit_pca_on_sample(veg_indices, n_components=1)\n",
    "\n",
    "        # Step 3: Apply PCA\n",
    "        pca_proj = apply_pca_to_batch(veg_indices, pca_model)\n",
    "\n",
    "        # Step 4: Multi-Otsu\n",
    "        binary_masks = apply_multi_otsu(pca_proj)\n",
    "\n",
    "        # Step 5: Morphological refinement\n",
    "        refined_masks = refine_masks_with_morphops(binary_masks)\n",
    "\n",
    "        # Step 6: Save\n",
    "        save_vegetation_masks(refined_masks, batch_paths)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    ms_per_image = (total_time / total_images) * 1000\n",
    "\n",
    "    print(f\"‚úÖ Completed {total_images} images in {total_time:.2f} sec\")\n",
    "    print(f\"‚ö° Avg processing time: {ms_per_image:.2f} ms/image\\n\")\n",
    "\n",
    "    return total_images, total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c10243e-78a0-4093-aa3f-cda909ca3bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting vegetation masking for train set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033f7d1d1b924dacbffa8e08612a482b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üå± Processing train:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1600 images in 65.75 sec\n",
      "‚ö° Avg processing time: 41.10 ms/image\n",
      "\n",
      "\n",
      "üöÄ Starting vegetation masking for val set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a176e1afe28c481c928780ba18dcb37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üå± Processing val:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 352 images in 12.62 sec\n",
      "‚ö° Avg processing time: 35.85 ms/image\n",
      "\n",
      "\n",
      "üöÄ Starting vegetation masking for test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91811d08e174d0dad0f33954b8c7dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üå± Processing test:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1200 images in 41.67 sec\n",
      "‚ö° Avg processing time: 34.73 ms/image\n",
      "\n",
      "üß† Total: 3152 images processed in 120.05 seconds\n",
      "üöÄ Overall Speed: 38.09 ms/image\n"
     ]
    }
   ],
   "source": [
    "# Aggregate total timing across all splits\n",
    "total_imgs_all = 0\n",
    "total_time_all = 0\n",
    "\n",
    "for loader, name in zip([train_loader, val_loader, test_loader], [\"train\", \"val\", \"test\"]):\n",
    "    imgs, time_taken = run_vegetation_masking_pipeline(loader, name)\n",
    "    total_imgs_all += imgs\n",
    "    total_time_all += time_taken\n",
    "\n",
    "# Final performance summary\n",
    "overall_ms_per_image = (total_time_all / total_imgs_all) * 1000\n",
    "print(f\"üß† Total: {total_imgs_all} images processed in {total_time_all:.2f} seconds\")\n",
    "print(f\"üöÄ Overall Speed: {overall_ms_per_image:.2f} ms/image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b32138-f9f5-4b95-918b-104f17d35dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
