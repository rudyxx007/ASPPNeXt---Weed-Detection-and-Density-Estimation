{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1870a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage.filters import threshold_multiotsu, threshold_otsu\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0dbb6c-19c3-4a54-92ee-de2535a59b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Single image processing\\nfinal_mask, individual_results, all_masks = process_single_image(\\n    \"path/to/your/image.jpg\", \\n    \"path/to/ground_truth.png\",  # Optional\\n    save_dir=\"./my_aevs_results\"\\n)\\n\\n# Batch processing\\nprocessed_images, aevs_model = batch_process_with_aevs(\\n    image_folder=\"path/to/images/\",\\n    ground_truth_folder=\"path/to/ground_truths/\",  # Optional\\n    save_dir=\"./batch_aevs_results\"\\n)\\n\\n# The vegetation masks will be automatically saved in:\\n# ./batch_aevs_results/masks/\\n# \\n# Models and results will be saved in:\\n# ./batch_aevs_results/models/\\n# ./batch_aevs_results/results/\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AdaptiveEnsembleVegetationSegmentation:\n",
    "    \"\"\"\n",
    "    Adaptive Ensemble Vegetation Segmentation (AEVS) Model\n",
    "    \n",
    "    This model combines:\n",
    "    1. Traditional vegetation indices (ExG, ExGR, CIVE, NGRDI, GLI, VEG)\n",
    "    2. Novel enhanced indices (AGDI, MVI, CVS, TVI)\n",
    "    3. Multi-method thresholding (Multi-Otsu, Watershed)\n",
    "    4. Unsupervised ML clustering\n",
    "    5. Ensemble decision fusion\n",
    "    \"\"\"\n",
    "    def __init__(self, save_dir=\"./aevs_results\"):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        self.svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name = \"AEVS\"\n",
    "        self.model_version = \"1.0\"\n",
    "        \n",
    "        # Create save directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, \"masks\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, \"indices\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, \"models\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, \"results\"), exist_ok=True)\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.results_log = []\n",
    "        self.best_method = None\n",
    "        self.best_accuracy = 0.0\n",
    "        \n",
    "def compute_indices(self, rgb_image):\n",
    "    R, G, B = rgb_image[:,:,0], rgb_image[:,:,1], rgb_image[:,:,2]\n",
    "    R = R.astype(np.float32) + 1e-8\n",
    "    G = G.astype(np.float32) + 1e-8\n",
    "    B = B.astype(np.float32) + 1e-8\n",
    "    \n",
    "    indices = {}\n",
    "\n",
    "    # ExG (Excess Green)\n",
    "    indices['ExG'] = 2*G - R - B\n",
    "    \n",
    "    # ExGR (Excess Green minus Excess Red)\n",
    "    ExR = 1.4*R - G\n",
    "    indices['ExGR'] = indices['ExG'] - ExR\n",
    "    \n",
    "    # CIVE (Color Index of Vegetation Extraction)\n",
    "    indices['CIVE'] = 0.441*R - 0.811*G + 0.385*B + 18.78745\n",
    "    \n",
    "    # NGRDI (Normalized Green Red Difference Index)\n",
    "    indices['NGRDI'] = (G - R) / (G + R)\n",
    "    \n",
    "    # GLI (Green Leaf Index)\n",
    "    indices['GLI'] = (2*G - R - B) / (2*G + R + B)\n",
    "    \n",
    "    # VEG (Vegetative Index)\n",
    "    indices['VEG'] = G / (R**0.667 * B**(1-0.667))\n",
    "    \n",
    "    # Adaptive Green Dominance Index (AGDI)\n",
    "    local_variance = cv2.Laplacian(rgb_image[:,:,1], cv2.CV_64F).var()\n",
    "    adaptive_factor = 1 + (local_variance / 10000)\n",
    "    indices['AGDI'] = adaptive_factor * (2*G - R - B) / (G + R + B)\n",
    "    \n",
    "    # Multi-scale Vegetation Index (MVI)\n",
    "    G_blur3 = cv2.GaussianBlur(G, (3,3), 0)\n",
    "    G_blur7 = cv2.GaussianBlur(G, (7,7), 0)\n",
    "    indices['MVI'] = (G + 0.5*G_blur3 + 0.25*G_blur7) / (R + B + 1e-8)\n",
    "    \n",
    "    # Chromatic Vegetation Strength (CVS)\n",
    "    intensity = (R + G + B) / 3\n",
    "    chromaticity_g = G / (R + G + B + 1e-8)\n",
    "    indices['CVS'] = chromaticity_g * np.log(intensity + 1)\n",
    "    \n",
    "    # Texture-aware Vegetation Index (TVI)\n",
    "    gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "    texture = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    texture_strength = np.abs(texture)\n",
    "    indices['TVI'] = (G - R) / (G + R) * (1 + texture_strength/255)\n",
    "    \n",
    "    return indices\n",
    "    \n",
    "    def multi_otsu_adaptive_threshold(self, index_image, n_classes=3):\n",
    "        \"\"\"Multi-Otsu thresholding as an alternative to standard Otsu\"\"\"\n",
    "        # Normalize the index\n",
    "        index_norm = ((index_image - index_image.min()) / \n",
    "                     (index_image.max() - index_image.min()) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Multi-Otsu thresholding\n",
    "        thresholds = threshold_multiotsu(index_norm, classes=n_classes)\n",
    "        \n",
    "        # Create segmentation (vegetation = highest class)\n",
    "        regions = np.digitize(index_norm, bins=thresholds)\n",
    "        vegetation_mask = (regions == (n_classes - 1)).astype(np.uint8)\n",
    "        \n",
    "        return vegetation_mask, thresholds\n",
    "    \n",
    "    def watershed_segmentation(self, index_image):\n",
    "        \"\"\"Watershed-based segmentation for better boundary detection\"\"\"\n",
    "        # Normalize and convert to uint8\n",
    "        index_norm = ((index_image - index_image.min()) / \n",
    "                     (index_image.max() - index_image.min()) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply Gaussian blur\n",
    "        blurred = cv2.GaussianBlur(index_norm, (5, 5), 0)\n",
    "        \n",
    "        # Find local maxima as markers\n",
    "        local_maxima = peak_local_maxima(blurred, min_distance=10, threshold_abs=50)\n",
    "        markers = np.zeros_like(blurred)\n",
    "        markers[tuple(local_maxima.T)] = np.arange(1, len(local_maxima) + 1)\n",
    "        \n",
    "        # Apply watershed\n",
    "        labels = watershed(-blurred, markers, mask=blurred > 30)\n",
    "        \n",
    "        # Convert to binary mask (non-zero regions are vegetation)\n",
    "        vegetation_mask = (labels > 0).astype(np.uint8)\n",
    "        \n",
    "        return vegetation_mask\n",
    "    \n",
    "    def ensemble_thresholding(self, indices_dict):\n",
    "        \"\"\"Ensemble approach combining multiple thresholding methods\"\"\"\n",
    "        masks = []\n",
    "        \n",
    "        for name, index in indices_dict.items():\n",
    "            # Method 1: Multi-Otsu\n",
    "            mask1, _ = self.multi_otsu_adaptive_threshold(index)\n",
    "            masks.append(mask1)\n",
    "            \n",
    "            # Method 2: Watershed\n",
    "            mask2 = self.watershed_segmentation(index)\n",
    "            masks.append(mask2)\n",
    "        \n",
    "        # Combine masks using majority voting\n",
    "        mask_stack = np.stack(masks, axis=-1)\n",
    "        ensemble_mask = (np.mean(mask_stack, axis=-1) > 0.5).astype(np.uint8)\n",
    "        \n",
    "        return ensemble_mask\n",
    "    \n",
    "    def individual_index_segmentation(self, rgb_image, method='otsu'):\n",
    "        all_indices = self.compute_indices(rgb_image)\n",
    "        \n",
    "        individual_results = {}\n",
    "        \n",
    "        for index_name, index_values in all_indices.items():\n",
    "            if method == 'otsu':\n",
    "                # Standard Otsu thresholding (like base paper)\n",
    "                index_norm = ((index_values - index_values.min()) / \n",
    "                             (index_values.max() - index_values.min()) * 255).astype(np.uint8)\n",
    "                threshold = threshold_otsu(index_norm)\n",
    "                mask = (index_norm > threshold).astype(np.uint8)\n",
    "            \n",
    "            elif method == 'multi_otsu':\n",
    "                # Multi-Otsu alternative\n",
    "                mask, _ = self.multi_otsu_adaptive_threshold(index_values)\n",
    "            \n",
    "            elif method == 'watershed':\n",
    "                # Watershed alternative\n",
    "                mask = self.watershed_segmentation(index_values)\n",
    "            \n",
    "            # Apply morphological refinement\n",
    "            refined_mask = self.morphological_refinement(mask)\n",
    "            \n",
    "            individual_results[index_name] = {\n",
    "                'mask': refined_mask,\n",
    "                'raw_mask': mask,\n",
    "                'index_values': index_values,\n",
    "                'method': method\n",
    "            }\n",
    "        \n",
    "        return individual_results\n",
    "    \n",
    "    def compare_individual_methods(self, rgb_image, ground_truth=None):\n",
    "        \"\"\"\n",
    "        Compare individual index performance (like base paper methodology)\n",
    "        \"\"\"\n",
    "        methods = ['otsu', 'multi_otsu', 'watershed']\n",
    "        comparison_results = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            individual_results = self.individual_index_segmentation(rgb_image, method)\n",
    "            comparison_results[method] = individual_results\n",
    "            \n",
    "            if ground_truth is not None:\n",
    "                # Evaluate each index\n",
    "                for index_name, result in individual_results.items():\n",
    "                    metrics = self.evaluate_segmentation(result['mask'], ground_truth)\n",
    "                    result['metrics'] = metrics\n",
    "                    \n",
    "                    print(f\"{method.upper()} - {index_name}: Accuracy = {metrics['accuracy']:.3f}\")\n",
    "        \n",
    "        return comparison_results\n",
    "        \"\"\"Apply morphological operations to refine the mask\"\"\"\n",
    "        # Remove small noise\n",
    "        kernel_small = np.ones((3,3), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small)\n",
    "        \n",
    "        # Fill small holes\n",
    "        kernel_medium = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_medium)\n",
    "        \n",
    "        # Remove small isolated regions\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "        min_area = 100  # Minimum area threshold\n",
    "        \n",
    "        refined_mask = np.zeros_like(mask)\n",
    "        for i in range(1, num_labels):\n",
    "            if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "                refined_mask[labels == i] = 1\n",
    "                \n",
    "    def save_vegetation_masks(self, masks_dict, image_name, method_name):\n",
    "        \"\"\"\n",
    "        Save vegetation masks for next phase of research\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        for mask_type, mask in masks_dict.items():\n",
    "            # Save as binary image (0-255)\n",
    "            mask_filename = f\"{image_name}_{method_name}_{mask_type}_{timestamp}.png\"\n",
    "            mask_path = os.path.join(self.save_dir, \"masks\", mask_filename)\n",
    "            cv2.imwrite(mask_path, mask.astype(np.uint8) * 255)\n",
    "            \n",
    "            # Also save as numpy array for easy loading\n",
    "            npy_filename = f\"{image_name}_{method_name}_{mask_type}_{timestamp}.npy\"\n",
    "            npy_path = os.path.join(self.save_dir, \"masks\", npy_filename)\n",
    "            np.save(npy_path, mask)\n",
    "        \n",
    "        print(f\"Masks saved for {image_name} using {method_name}\")\n",
    "    \n",
    "    def save_model_state(self, image_name):\n",
    "        \"\"\"\n",
    "        Save the current model state and parameters\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        model_state = {\n",
    "            'model_name': self.model_name,\n",
    "            'model_version': self.model_version,\n",
    "            'timestamp': timestamp,\n",
    "            'scaler': self.scaler,\n",
    "            'best_method': self.best_method,\n",
    "            'best_accuracy': self.best_accuracy,\n",
    "            'results_log': self.results_log\n",
    "        }\n",
    "        \n",
    "        # Save model state\n",
    "        model_filename = f\"aevs_model_{image_name}_{timestamp}.pkl\"\n",
    "        model_path = os.path.join(self.save_dir, \"models\", model_filename)\n",
    "        \n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model_state, f)\n",
    "        \n",
    "        print(f\"Model state saved: {model_filename}\")\n",
    "        return model_path\n",
    "    \n",
    "    def save_results_summary(self, results, image_name):\n",
    "        \"\"\"\n",
    "        Save comprehensive results summary\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        json_results = {}\n",
    "        for method, method_data in results.items():\n",
    "            json_results[method] = {}\n",
    "            for index_name, index_data in method_data.items():\n",
    "                json_results[method][index_name] = {\n",
    "                    'method': index_data['method'],\n",
    "                    'metrics': index_data.get('metrics', {}),\n",
    "                    'mask_shape': index_data['mask'].shape,\n",
    "                    'mask_coverage': float(np.sum(index_data['mask']) / index_data['mask'].size)\n",
    "                }\n",
    "        \n",
    "        # Save as JSON\n",
    "        results_filename = f\"results_{image_name}_{timestamp}.json\"\n",
    "        results_path = os.path.join(self.save_dir, \"results\", results_filename)\n",
    "        \n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(json_results, f, indent=2)\n",
    "        \n",
    "        print(f\"Results summary saved: {results_filename}\")\n",
    "        return results_path\n",
    "    \n",
    "        return refined_mask\n",
    "    \n",
    "    def aevs_segmentation(self, rgb_image):\n",
    "        \"\"\"\n",
    "        Main AEVS model segmentation method\n",
    "        This is the novel ensemble approach\n",
    "        \"\"\"\n",
    "        # Step 1: Compute all indices\n",
    "        all_indices = self.compute_indices(rgb_image)\n",
    "        \n",
    "        # Step 2: Individual method results\n",
    "        individual_otsu = self.individual_index_segmentation(rgb_image, 'otsu')\n",
    "        individual_multi_otsu = self.individual_index_segmentation(rgb_image, 'multi_otsu')\n",
    "        individual_watershed = self.individual_index_segmentation(rgb_image, 'watershed')\n",
    "        \n",
    "        # Step 3: ML-based segmentation\n",
    "        ml_mask = self.unsupervised_ml_segmentation(rgb_image)\n",
    "        \n",
    "        # Step 4: Ensemble decision making\n",
    "        all_masks = []\n",
    "        \n",
    "        # Collect masks from different methods\n",
    "        for method_results in [individual_otsu, individual_multi_otsu, individual_watershed]:\n",
    "            for index_name, result in method_results.items():\n",
    "                all_masks.append(result['mask'])\n",
    "        \n",
    "        # Add ML mask\n",
    "        all_masks.append(ml_mask)\n",
    "        \n",
    "        # Ensemble voting\n",
    "        mask_stack = np.stack(all_masks, axis=-1)\n",
    "        ensemble_mask = (np.mean(mask_stack, axis=-1) > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Step 5: Final refinement\n",
    "        final_mask = self.morphological_refinement(ensemble_mask)\n",
    "        \n",
    "        return final_mask, all_indices, {\n",
    "            'individual_otsu': individual_otsu,\n",
    "            'individual_multi_otsu': individual_multi_otsu,\n",
    "            'individual_watershed': individual_watershed,\n",
    "            'ml_mask': ml_mask,\n",
    "            'ensemble_mask': ensemble_mask,\n",
    "            'final_mask': final_mask\n",
    "        }\n",
    "    \n",
    "    def process_and_save_image(self, rgb_image, image_name, ground_truth=None):\n",
    "        \"\"\"\n",
    "        Complete processing pipeline with saving functionality\n",
    "        \"\"\"\n",
    "        print(f\"\\nProcessing image: {image_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Step 1: Compare individual methods (like base paper)\n",
    "        print(\"1. Individual Index Comparison (Base Paper Approach):\")\n",
    "        individual_comparison = self.compare_individual_methods(rgb_image, ground_truth)\n",
    "        \n",
    "        # Step 2: Apply AEVS model\n",
    "        print(\"\\n2. AEVS Ensemble Model:\")\n",
    "        aevs_mask, indices, all_masks = self.aevs_segmentation(rgb_image)\n",
    "        \n",
    "        # Step 3: Evaluate AEVS if ground truth available\n",
    "        if ground_truth is not None:\n",
    "            aevs_metrics = self.evaluate_segmentation(aevs_mask, ground_truth)\n",
    "            print(f\"AEVS Model Accuracy: {aevs_metrics['accuracy']:.3f}\")\n",
    "            \n",
    "            # Track best method\n",
    "            if aevs_metrics['accuracy'] > self.best_accuracy:\n",
    "                self.best_accuracy = aevs_metrics['accuracy']\n",
    "                self.best_method = 'AEVS_Ensemble'\n",
    "        \n",
    "        # Step 4: Save all masks\n",
    "        masks_to_save = {\n",
    "            'aevs_final': aevs_mask,\n",
    "            'aevs_ensemble': all_masks['ensemble_mask'],\n",
    "            'aevs_ml': all_masks['ml_mask']\n",
    "        }\n",
    "        \n",
    "        # Add best individual masks from each method\n",
    "        for method_name, method_results in individual_comparison.items():\n",
    "            best_index = None\n",
    "            best_acc = 0\n",
    "            \n",
    "            if ground_truth is not None:\n",
    "                for index_name, result in method_results.items():\n",
    "                    if 'metrics' in result and result['metrics']['accuracy'] > best_acc:\n",
    "                        best_acc = result['metrics']['accuracy']\n",
    "                        best_index = index_name\n",
    "            else:\n",
    "                # If no ground truth, use first index\n",
    "                best_index = list(method_results.keys())[0]\n",
    "            \n",
    "            if best_index:\n",
    "                masks_to_save[f'best_{method_name}_{best_index}'] = method_results[best_index]['mask']\n",
    "        \n",
    "        # Save masks\n",
    "        self.save_vegetation_masks(masks_to_save, image_name, 'AEVS')\n",
    "        \n",
    "        # Step 5: Save indices\n",
    "        indices_filename = f\"indices_{image_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "        indices_path = os.path.join(self.save_dir, \"indices\", indices_filename)\n",
    "        with open(indices_path, 'wb') as f:\n",
    "            pickle.dump(indices, f)\n",
    "        \n",
    "        # Step 6: Save results summary\n",
    "        results_summary = {\n",
    "            'individual_comparison': individual_comparison,\n",
    "            'aevs_results': {\n",
    "                'final_mask_shape': aevs_mask.shape,\n",
    "                'vegetation_coverage': float(np.sum(aevs_mask) / aevs_mask.size),\n",
    "                'metrics': aevs_metrics if ground_truth is not None else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.save_results_summary({'aevs': results_summary}, image_name)\n",
    "        \n",
    "        # Step 7: Save model state\n",
    "        self.save_model_state(image_name)\n",
    "        \n",
    "        # Step 8: Log results\n",
    "        result_entry = {\n",
    "            'image_name': image_name,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'aevs_accuracy': aevs_metrics['accuracy'] if ground_truth is not None else None,\n",
    "            'vegetation_coverage': float(np.sum(aevs_mask) / aevs_mask.size)\n",
    "        }\n",
    "        self.results_log.append(result_entry)\n",
    "        \n",
    "        return aevs_mask, individual_comparison, all_masks\n",
    "        \n",
    "        all_indices = self.compute_indices(rgb_image)\n",
    "        \n",
    "        features = []\n",
    "        for name, index in all_indices.items():\n",
    "            features.append(index.flatten())\n",
    "        \n",
    "        feature_matrix = np.column_stack(features)\n",
    "        \n",
    "        # Add spatial coordinates as features (normalized)\n",
    "        h, w = rgb_image.shape[:2]\n",
    "        y_coords, x_coords = np.meshgrid(range(h), range(w), indexing='ij')\n",
    "        x_norm = x_coords.flatten() / w\n",
    "        y_norm = y_coords.flatten() / h\n",
    "        \n",
    "        # Add RGB values\n",
    "        r_flat = rgb_image[:,:,0].flatten() / 255.0\n",
    "        g_flat = rgb_image[:,:,1].flatten() / 255.0\n",
    "        b_flat = rgb_image[:,:,2].flatten() / 255.0\n",
    "        \n",
    "        # Combine all features\n",
    "        final_features = np.column_stack([feature_matrix, x_norm, y_norm, r_flat, g_flat, b_flat])\n",
    "        \n",
    "        return final_features, all_indices\n",
    "    \n",
    "    def unsupervised_ml_segmentation(self, rgb_image, method='kmeans'):\n",
    "        \"\"\"Unsupervised ML-based segmentation\"\"\"\n",
    "        features, indices = self.prepare_feature_vector(rgb_image)\n",
    "        \n",
    "        # Normalize features\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        \n",
    "        if method == 'kmeans':\n",
    "            # K-means clustering (2 clusters: vegetation vs background)\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(features_scaled)\n",
    "            \n",
    "            # Determine which cluster is vegetation (assume cluster with higher green index)\n",
    "            cluster_0_mean_exg = np.mean(indices['ExG'].flatten()[labels == 0])\n",
    "            cluster_1_mean_exg = np.mean(indices['ExG'].flatten()[labels == 1])\n",
    "            \n",
    "            vegetation_cluster = 1 if cluster_1_mean_exg > cluster_0_mean_exg else 0\n",
    "            vegetation_mask = (labels == vegetation_cluster).reshape(rgb_image.shape[:2]).astype(np.uint8)\n",
    "            \n",
    "        return vegetation_mask\n",
    "    \n",
    "    def hybrid_segmentation(self, rgb_image):\n",
    "        \"\"\"Novel hybrid approach combining multiple methods\"\"\"\n",
    "        # Step 1: Compute all indices\n",
    "        all_indices = self.compute_indices(rgb_image)\n",
    "        \n",
    "        # Step 2: Ensemble thresholding\n",
    "        threshold_mask = self.ensemble_thresholding(all_indices)\n",
    "        \n",
    "        # Step 3: ML-based segmentation\n",
    "        ml_mask = self.unsupervised_ml_segmentation(rgb_image)\n",
    "        \n",
    "        # Step 4: Combine both approaches\n",
    "        combined_mask = np.logical_and(threshold_mask, ml_mask).astype(np.uint8)\n",
    "        \n",
    "        # Step 5: Morphological refinement\n",
    "        final_mask = self.morphological_refinement(combined_mask)\n",
    "        \n",
    "        return final_mask, all_indices\n",
    "    \n",
    "    def evaluate_segmentation(self, predicted_mask, ground_truth_mask):\n",
    "        \"\"\"Evaluate segmentation performance\"\"\"\n",
    "        # Flatten masks\n",
    "        pred_flat = predicted_mask.flatten()\n",
    "        gt_flat = ground_truth_mask.flatten()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(gt_flat, pred_flat)\n",
    "        \n",
    "        # Calculate IoU (Intersection over Union)\n",
    "        intersection = np.sum(pred_flat & gt_flat)\n",
    "        union = np.sum(pred_flat | gt_flat)\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        tp = np.sum(pred_flat & gt_flat)\n",
    "        fp = np.sum(pred_flat & ~gt_flat)\n",
    "        fn = np.sum(~pred_flat & gt_flat)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'iou': iou,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "    \n",
    "    def visualize_results(self, rgb_image, mask, indices_dict):\n",
    "        \"\"\"Visualize segmentation results\"\"\"\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0,0].imshow(rgb_image)\n",
    "        axes[0,0].set_title('Original Image')\n",
    "        \n",
    "        # Final mask\n",
    "        axes[0,1].imshow(mask, cmap='gray')\n",
    "        axes[0,1].set_title('Vegetation Mask')\n",
    "        \n",
    "        # Overlay\n",
    "        overlay = rgb_image.copy()\n",
    "        overlay[mask == 1] = [0, 255, 0]  # Green overlay for vegetation\n",
    "        axes[0,2].imshow(overlay)\n",
    "        axes[0,2].set_title('Overlay')\n",
    "        axes[0,2].axis('off')\n",
    "        \n",
    "        # Show some key indices\n",
    "        key_indices = ['ExG', 'AGDI', 'MVI', 'CVS']\n",
    "        for i, idx_name in enumerate(key_indices):\n",
    "            if idx_name in indices_dict:\n",
    "                if i < 3:\n",
    "                    axes[0,3].imshow(indices_dict[idx_name], cmap='viridis')\n",
    "                    axes[0,3].set_title(f'{idx_name}')\n",
    "                    axes[0,3].axis('off')\n",
    "                else:\n",
    "                    axes[1,i-3].imshow(indices_dict[idx_name], cmap='viridis')\n",
    "                    axes[1,i-3].set_title(f'{idx_name}')\n",
    "                    axes[1,i-3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def morphological_refinement(self, mask):\n",
    "        \"\"\"Apply morphological operations to refine the mask\"\"\"\n",
    "        # Remove small noise\n",
    "        kernel_small = np.ones((3,3), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small)\n",
    "        \n",
    "        # Fill small holes\n",
    "        kernel_medium = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_medium)\n",
    "        \n",
    "        # Remove small isolated regions\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "        min_area = 100  # Minimum area threshold\n",
    "        \n",
    "        refined_mask = np.zeros_like(mask)\n",
    "        for i in range(1, num_labels):\n",
    "            if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "                refined_mask[labels == i] = 1\n",
    "\n",
    "# Example usage functions\n",
    "def process_single_image(image_path, ground_truth_path=None, save_dir=\"./aevs_results\"):\n",
    "    \"\"\"\n",
    "    Process a single image with the AEVS model\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load ground truth if available\n",
    "    ground_truth = None\n",
    "    if ground_truth_path:\n",
    "        ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
    "        ground_truth = (ground_truth > 127).astype(np.uint8)  # Binarize\n",
    "    \n",
    "    # Get image name\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    \n",
    "    # Initialize AEVS model\n",
    "    aevs_model = AdaptiveEnsembleVegetationSegmentation(save_dir=save_dir)\n",
    "    \n",
    "    # Process and save\n",
    "    final_mask, individual_results, all_masks = aevs_model.process_and_save_image(\n",
    "        image, image_name, ground_truth\n",
    "    )\n",
    "    \n",
    "    # Visualize results\n",
    "    aevs_model.visualize_results(image, final_mask, \n",
    "                                aevs_model.compute_traditional_indices(image))\n",
    "    \n",
    "    return final_mask, individual_results, all_masks\n",
    "\n",
    "def batch_process_with_aevs(image_folder, ground_truth_folder=None, save_dir=\"./aevs_batch_results\"):\n",
    "    \"\"\"\n",
    "    Batch process images with AEVS model\n",
    "    \"\"\"\n",
    "    aevs_model = AdaptiveEnsembleVegetationSegmentation(save_dir=save_dir)\n",
    "    \n",
    "    processed_images = []\n",
    "    \n",
    "    for image_file in os.listdir(image_folder):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"\\nProcessing: {image_file}\")\n",
    "            \n",
    "            # Load image\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Load ground truth if available\n",
    "            ground_truth = None\n",
    "            if ground_truth_folder:\n",
    "                gt_file = image_file.replace('.jpg', '.png').replace('.jpeg', '.png')\n",
    "                gt_path = os.path.join(ground_truth_folder, gt_file)\n",
    "                if os.path.exists(gt_path):\n",
    "                    ground_truth = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    ground_truth = (ground_truth > 127).astype(np.uint8)\n",
    "            \n",
    "            # Process image\n",
    "            image_name = os.path.splitext(image_file)[0]\n",
    "            final_mask, individual_results, all_masks = aevs_model.process_and_save_image(\n",
    "                image, image_name, ground_truth\n",
    "            )\n",
    "            \n",
    "            processed_images.append({\n",
    "                'image_file': image_file,\n",
    "                'final_mask': final_mask,\n",
    "                'individual_results': individual_results,\n",
    "                'all_masks': all_masks\n",
    "            })\n",
    "    \n",
    "    # Generate final summary report\n",
    "    generate_final_report(aevs_model, save_dir)\n",
    "    \n",
    "    return processed_images, aevs_model\n",
    "\n",
    "def generate_final_report(aevs_model, save_dir):\n",
    "    \"\"\"\n",
    "    Generate final performance report\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        'model_info': {\n",
    "            'name': aevs_model.model_name,\n",
    "            'version': aevs_model.model_version,\n",
    "            'total_images_processed': len(aevs_model.results_log)\n",
    "        },\n",
    "        'performance_summary': {\n",
    "            'best_method': aevs_model.best_method,\n",
    "            'best_accuracy': aevs_model.best_accuracy,\n",
    "            'average_vegetation_coverage': np.mean([r['vegetation_coverage'] for r in aevs_model.results_log])\n",
    "        },\n",
    "        'detailed_results': aevs_model.results_log\n",
    "    }\n",
    "    \n",
    "    # Save report\n",
    "    report_path = os.path.join(save_dir, \"final_report.json\")\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nFinal report saved: {report_path}\")\n",
    "    print(f\"Best Method: {aevs_model.best_method}\")\n",
    "    print(f\"Best Accuracy: {aevs_model.best_accuracy:.3f}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Usage Examples:\n",
    "\"\"\"\n",
    "# Single image processing\n",
    "final_mask, individual_results, all_masks = process_single_image(\n",
    "    \"path/to/your/image.jpg\", \n",
    "    \"path/to/ground_truth.png\",  # Optional\n",
    "    save_dir=\"./my_aevs_results\"\n",
    ")\n",
    "\n",
    "# Batch processing\n",
    "processed_images, aevs_model = batch_process_with_aevs(\n",
    "    image_folder=\"path/to/images/\",\n",
    "    ground_truth_folder=\"path/to/ground_truths/\",  # Optional\n",
    "    save_dir=\"./batch_aevs_results\"\n",
    ")\n",
    "\n",
    "# The vegetation masks will be automatically saved in:\n",
    "# ./batch_aevs_results/masks/\n",
    "# \n",
    "# Models and results will be saved in:\n",
    "# ./batch_aevs_results/models/\n",
    "# ./batch_aevs_results/results/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd61f9c-4719-4d39-803c-06e777605169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
